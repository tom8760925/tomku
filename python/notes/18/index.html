<!doctype html><html lang=en-us dir=ltr><head><meta charset=utf-8><meta name=viewport content="width=device-width"><title>python語言的筆記-pytorch-圖像AI模型 | tomku的網誌
</title><link rel=stylesheet href=/tomku/css/cssall.min.6db1d46d747ddea4cd158fef8a0e6f577651a77ebbe8bf96fc205497064d9dcf.css><script src=/tomku/js/main.js></script><script src=/tomku/js/header.js></script></head><body><header class=baseof_header_class><nav class=header_nav_class><div id=header_div_left class=header_div_class><a href=/tomku/><h1 class=header_h1_class>tomku的網誌</h1></a></div><div id=header_div_right class=header_div_class><ul class=header_menu_ul_class><li class=header_menu_li_class><a class=header_menu_a_class href=/tomku/>首頁</a></li><li class=header_menu_li_class><a class=header_menu_a_class2 onclick='displaymenu("header_menu_li_class_1")'>程式</a><ul id=header_menu_li_class_1 class=header_menu_ul_class2><li class=header_menu_li_class2><a class=header_menu_a_class href=/tomku/c/>C</a></li><li class=header_menu_li_class2><a class=header_menu_a_class href=/tomku/c++/>C++</a></li><li class=header_menu_li_class2><a class=header_menu_a_class href=/tomku/golang/>golang</a></li><li class=header_menu_li_class2><a class=header_menu_a_class href=/tomku/java/>java</a></li><li class=header_menu_li_class2><a class=header_menu_a_class href=/tomku/python/>python</a></li><li class=header_menu_li_class2><a class=header_menu_a_class href=/tomku/csharp/>csharp</a></li></ul></li><li class=header_menu_li_class><a class=header_menu_a_class2 onclick='displaymenu("header_menu_li_class_2")'>其他</a><ul id=header_menu_li_class_2 class=header_menu_ul_class2><li class=header_menu_li_class2><a class=header_menu_a_class href=/tomku/esp/>esp</a></li><li class=header_menu_li_class2><a class=header_menu_a_class href=/tomku/git/>git</a></li><li class=header_menu_li_class2><a class=header_menu_a_class href=/tomku/hugo/>hugo</a></li><li class=header_menu_li_class2><a class=header_menu_a_class href=/tomku/mysql/>mysql</a></li><li class=header_menu_li_class2><a class=header_menu_a_class href=/tomku/minecraft/>minecraft</a></li><li class=header_menu_li_class2><a class=header_menu_a_class href=/tomku/qt/>qt</a></li><li class=header_menu_li_class2><a class=header_menu_a_class href=/tomku/linux/>linux</a></li><li class=header_menu_li_class2><a class=header_menu_a_class href=/tomku/other/>other</a></li></ul></li><li class=header_menu_li_class><a class=header_menu_a_class href=/tomku/tags/>標籤</a></li><li class=header_menu_li_class><a class=header_menu_a_class href=/tomku/about/>關於</a></li></ul></div></nav></header><main class=baseof_main_class><aside class="main left_aside_class"><div class=left_div_class3><button class=left_button_class onclick=displayleft()>☰</button></div><div id=left_div_class4 class=left_div_class4><div class=left_div_class><div class=left_div_class2>個人連結</div><div class=left_social_div_class><ul class=left_social_ul_class><li class=left_social_li_class><a href=https://github.com/tom8760925 class=left_social_a_class>github</a></li><li class=left_social_li_class><a href=https://www.notion.so/tomku-1dafd63b811e80debc8fe145cc6d494a class=left_social_a_class>副網誌</a></li></ul></div></div><div class=left_div_class><div class=left_div_class2>最新文章</div><nav><ul class=left_recent_ul_class><li class=left_recent_li_class><article><header class=left_recent_header_class><a href=/tomku/python/notes/19/>python語言的筆記-pytorch-文字AI模型</a></header><footer class=left_recent_footer_class><time datetime=2025-10-18T15:07:01+08:00>2025-10-18</time></footer><a class=left_recent_a_class href=/tomku/python/notes/19/></a></article></li><li class=left_recent_li_class><article><header class=left_recent_header_class><a href=/tomku/python/notes/18/>python語言的筆記-pytorch-圖像AI模型</a></header><footer class=left_recent_footer_class><time datetime=2025-09-30T17:24:43+08:00>2025-09-30</time></footer><a class=left_recent_a_class href=/tomku/python/notes/18/></a></article></li><li class=left_recent_li_class><article><header class=left_recent_header_class><a href=/tomku/ai/no/08/>AI的練習-深度學習</a></header><footer class=left_recent_footer_class><time datetime=2025-09-08T15:56:10+08:00>2025-09-08</time></footer><a class=left_recent_a_class href=/tomku/ai/no/08/></a></article></li><li class=left_recent_li_class><article><header class=left_recent_header_class><a href=/tomku/ai/no/07/>AI的練習-其他</a></header><footer class=left_recent_footer_class><time datetime=2025-09-08T14:01:40+08:00>2025-09-08</time></footer><a class=left_recent_a_class href=/tomku/ai/no/07/></a></article></li><li class=left_recent_li_class><article><header class=left_recent_header_class><a href=/tomku/python/practice/focus14/>python語言的練習-練習實作重點14-變數範圍</a></header><footer class=left_recent_footer_class><time datetime=2025-09-08T13:33:10+08:00>2025-09-08</time></footer><a class=left_recent_a_class href=/tomku/python/practice/focus14/></a></article></li></ul></nav></div><div class=left_div_class><div class=left_div_class2>標籤</div><div class=left_tags_div_class><a href=/tomku/categories/ai/ class=left_tags_a_class>Ai<sup>10</sup>
</a><a href=/tomku/categories/c++%E8%AA%9E%E8%A8%80/ class=left_tags_a_class>C++語言<sup>169</sup>
</a><a href=/tomku/categories/cmake/ class=left_tags_a_class>Cmake<sup>2</sup>
</a><a href=/tomku/categories/csharp%E8%AA%9E%E8%A8%80/ class=left_tags_a_class>Csharp語言<sup>1</sup>
</a><a href=/tomku/categories/c%E8%AA%9E%E8%A8%80/ class=left_tags_a_class>C語言<sup>22</sup>
</a><a href=/tomku/categories/esp/ class=left_tags_a_class>Esp<sup>9</sup>
</a><a href=/tomku/categories/git/ class=left_tags_a_class>Git<sup>1</sup>
</a><a href=/tomku/categories/golang%E8%AA%9E%E8%A8%80/ class=left_tags_a_class>Golang語言<sup>20</sup>
</a><a href=/tomku/categories/hugo/ class=left_tags_a_class>Hugo<sup>3</sup>
</a><a href=/tomku/categories/linux/ class=left_tags_a_class>Linux<sup>30</sup>
</a><a href=/tomku/categories/minecraft/ class=left_tags_a_class>Minecraft<sup>6</sup>
</a><a href=/tomku/categories/mysql/ class=left_tags_a_class>Mysql<sup>3</sup>
</a><a href=/tomku/categories/proxomx/ class=left_tags_a_class>Proxomx<sup>3</sup>
</a><a href=/tomku/categories/python%E8%AA%9E%E8%A8%80/ class=left_tags_a_class>Python語言<sup>34</sup>
</a><a href=/tomku/categories/qt/ class=left_tags_a_class>Qt<sup>11</sup>
</a><a href=/tomku/categories/xcode/ class=left_tags_a_class>Xcode<sup>3</sup>
</a><a href=/tomku/categories/%E5%85%B6%E4%BB%96/ class=left_tags_a_class>其他<sup>1</sup>
</a><a href=/tomku/categories/%E9%97%9C%E6%96%BC/ class=left_tags_a_class>關於<sup>1</sup></a></div></div></div></aside><div class="main main_div_class"><section class=main_page_section_class><article><header><div class=main_page_breadcrumb_div_class><a href=/tomku/>簡介
</a>/<a href=/tomku/python/>Pythons
</a>/<a href=/tomku/python/notes/>筆記
</a>/</div><h1 class=main_page_h1_class>python語言的筆記-pytorch-圖像AI模型</h1></header><time class=main_page_time_class datetime=2025-09-30T17:24:43+08:00>2025-09-30</time><div class=main_page_div_class2><h1 id=pytorch-圖像ai模型>pytorch-圖像AI模型</h1><p>這篇是python的筆記第18篇</p><h2 id=監督式>監督式</h2><h3 id=cnn>cnn</h3><p>最簡單辨識圖像模型</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py><span style=display:flex><span><span style=color:#f92672>import</span> torch
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> torch <span style=color:#f92672>import</span> nn, optim
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> torch.utils.data <span style=color:#f92672>import</span> TensorDataset, DataLoader, random_split
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> torchvision <span style=color:#f92672>import</span> datasets, transforms
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> tqdm <span style=color:#f92672>import</span> tqdm
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 使用顯卡或cpu執行</span>
</span></span><span style=display:flex><span>device <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>device(<span style=color:#e6db74>&#39;cuda&#39;</span> <span style=color:#66d9ef>if</span> torch<span style=color:#f92672>.</span>cuda<span style=color:#f92672>.</span>is_available() <span style=color:#66d9ef>else</span> <span style=color:#e6db74>&#39;cpu&#39;</span>)
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;使用的設備: </span><span style=color:#e6db74>{</span>device<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 將資料轉換</span>
</span></span><span style=display:flex><span>transform <span style=color:#f92672>=</span> transforms<span style=color:#f92672>.</span>Compose([
</span></span><span style=display:flex><span>    <span style=color:#75715e># 將資料轉換Tensor 格式</span>
</span></span><span style=display:flex><span>    transforms<span style=color:#f92672>.</span>PILToTensor(),
</span></span><span style=display:flex><span>    <span style=color:#75715e># 轉換型態</span>
</span></span><span style=display:flex><span>    transforms<span style=color:#f92672>.</span>ConvertImageDtype(torch<span style=color:#f92672>.</span>float)
</span></span><span style=display:flex><span>])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 載入訓練集，載入位置，是否為訓練集，如果沒有就下載</span>
</span></span><span style=display:flex><span>trainset <span style=color:#f92672>=</span> datasets<span style=color:#f92672>.</span>CIFAR10(
</span></span><span style=display:flex><span>    root<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;./data&#39;</span>, 
</span></span><span style=display:flex><span>    train<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>, 
</span></span><span style=display:flex><span>    download<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>,
</span></span><span style=display:flex><span>    transform<span style=color:#f92672>=</span>transform
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span><span style=color:#75715e># 載入測試集，載入位置，是否為訓練集，如果沒有就下載</span>
</span></span><span style=display:flex><span>testset <span style=color:#f92672>=</span> datasets<span style=color:#f92672>.</span>CIFAR10(
</span></span><span style=display:flex><span>    root<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;./data&#39;</span>, 
</span></span><span style=display:flex><span>    train<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>, 
</span></span><span style=display:flex><span>    download<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>,
</span></span><span style=display:flex><span>    transform<span style=color:#f92672>=</span>transform
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 分割訓練集8:2分 (訓練集與驗證集)</span>
</span></span><span style=display:flex><span>train_size <span style=color:#f92672>=</span> int((<span style=color:#ae81ff>1</span> <span style=color:#f92672>-</span> <span style=color:#ae81ff>0.2</span>) <span style=color:#f92672>*</span> len(trainset))
</span></span><span style=display:flex><span>val_size <span style=color:#f92672>=</span> len(trainset) <span style=color:#f92672>-</span> train_size
</span></span><span style=display:flex><span>train_dataset, val_dataset <span style=color:#f92672>=</span> random_split(trainset, [train_size, val_size])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 資料集分群批</span>
</span></span><span style=display:flex><span>BATCH_SIZE <span style=color:#f92672>=</span> <span style=color:#ae81ff>64</span>
</span></span><span style=display:flex><span>trainloader <span style=color:#f92672>=</span> DataLoader(train_dataset, batch_size<span style=color:#f92672>=</span>BATCH_SIZE, shuffle<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span><span style=display:flex><span>valloader <span style=color:#f92672>=</span> DataLoader(val_dataset, batch_size<span style=color:#f92672>=</span>BATCH_SIZE, shuffle<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>)
</span></span><span style=display:flex><span>testloader <span style=color:#f92672>=</span> DataLoader(testset, batch_size<span style=color:#f92672>=</span>BATCH_SIZE, shuffle<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 模型</span>
</span></span><span style=display:flex><span>model <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Sequential(
</span></span><span style=display:flex><span>    <span style=color:#75715e># 卷積層 找出圖片特徵，在圖片中找出32個3x3大小範圍內的特徵，並將小於0值為0，輸入為3層</span>
</span></span><span style=display:flex><span>    nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>3</span>,<span style=color:#ae81ff>32</span>, (<span style=color:#ae81ff>3</span>,<span style=color:#ae81ff>3</span>), padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>), nn<span style=color:#f92672>.</span>ReLU(),
</span></span><span style=display:flex><span>    <span style=color:#75715e># 池化層 減少值數量找到最大值，以2x2大小找</span>
</span></span><span style=display:flex><span>    nn<span style=color:#f92672>.</span>MaxPool2d(<span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>2</span>),
</span></span><span style=display:flex><span>    <span style=color:#75715e># 卷積層 找出圖片特徵，在圖片中找出64個3x3大小範圍內的特徵，並將小於0值為0，輸入為32層</span>
</span></span><span style=display:flex><span>    nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>32</span>, <span style=color:#ae81ff>64</span>, (<span style=color:#ae81ff>3</span>,<span style=color:#ae81ff>3</span>), padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>), nn<span style=color:#f92672>.</span>ReLU(),
</span></span><span style=display:flex><span>    <span style=color:#75715e># 池化層 減少值數量找到最大值，以2x2大小找</span>
</span></span><span style=display:flex><span>    nn<span style=color:#f92672>.</span>MaxPool2d(<span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>2</span>),
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#75715e># 卷積層 找出圖片特徵，在圖片中找出64個3x3大小範圍內的特徵，並將小於0值為0，輸入為64層</span>
</span></span><span style=display:flex><span>    nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>64</span>, <span style=color:#ae81ff>64</span>, (<span style=color:#ae81ff>3</span>,<span style=color:#ae81ff>3</span>), padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>), nn<span style=color:#f92672>.</span>ReLU(),
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#75715e># 攤平層 將二維轉換一維</span>
</span></span><span style=display:flex><span>    nn<span style=color:#f92672>.</span>Flatten(),
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#75715e># 全連接層 將攤平層整理出64的輸出，輸入為64*8*8</span>
</span></span><span style=display:flex><span>    nn<span style=color:#f92672>.</span>Linear(<span style=color:#ae81ff>64</span> <span style=color:#f92672>*</span> <span style=color:#ae81ff>8</span> <span style=color:#f92672>*</span> <span style=color:#ae81ff>8</span>, <span style=color:#ae81ff>64</span>), nn<span style=color:#f92672>.</span>ReLU(),
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#75715e># 全連接層 最後整理輸出訓練集所分類的10個，輸入為64</span>
</span></span><span style=display:flex><span>    nn<span style=color:#f92672>.</span>Linear(<span style=color:#ae81ff>64</span>, <span style=color:#ae81ff>10</span>)
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>)<span style=color:#f92672>.</span>to(device)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 設定損失</span>
</span></span><span style=display:flex><span>criterion <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>CrossEntropyLoss()
</span></span><span style=display:flex><span><span style=color:#75715e># 設定優化</span>
</span></span><span style=display:flex><span>optimizer <span style=color:#f92672>=</span> optim<span style=color:#f92672>.</span>Adam(model<span style=color:#f92672>.</span>parameters(), lr<span style=color:#f92672>=</span><span style=color:#ae81ff>0.001</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>NUM_EPOCHS <span style=color:#f92672>=</span> <span style=color:#ae81ff>1</span> 
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 設定訓練次數</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> epoch <span style=color:#f92672>in</span> range(NUM_EPOCHS):
</span></span><span style=display:flex><span>    <span style=color:#75715e># 初始化損失和準確和數量</span>
</span></span><span style=display:flex><span>    total_loss, total_correct, total_count <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#75715e># 設定進度條，將訓練集載入</span>
</span></span><span style=display:flex><span>    train_loop <span style=color:#f92672>=</span> tqdm(
</span></span><span style=display:flex><span>        trainloader, 
</span></span><span style=display:flex><span>        desc<span style=color:#f92672>=</span><span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Epoch </span><span style=color:#e6db74>{</span>epoch <span style=color:#f92672>+</span> <span style=color:#ae81ff>1</span><span style=color:#e6db74>}</span><span style=color:#e6db74>/</span><span style=color:#e6db74>{</span><span style=color:#ae81ff>1</span><span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>, 
</span></span><span style=display:flex><span>        unit<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;batch&#34;</span>,
</span></span><span style=display:flex><span>        leave<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>
</span></span><span style=display:flex><span>    )
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#75715e># 使用進度調</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> inputs, labels <span style=color:#f92672>in</span> train_loop:
</span></span><span style=display:flex><span>        <span style=color:#75715e># 訓練集設定設備</span>
</span></span><span style=display:flex><span>        inputs, labels <span style=color:#f92672>=</span> inputs<span style=color:#f92672>.</span>to(device), labels<span style=color:#f92672>.</span>to(device)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># 梯度歸零，因為pytocrh的梯度不會規零，主要原因是批次訓練</span>
</span></span><span style=display:flex><span>        optimizer<span style=color:#f92672>.</span>zero_grad() 
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        <span style=color:#75715e># 執行模型</span>
</span></span><span style=display:flex><span>        outputs <span style=color:#f92672>=</span> model(inputs)
</span></span><span style=display:flex><span>        <span style=color:#75715e># 取得損失</span>
</span></span><span style=display:flex><span>        loss <span style=color:#f92672>=</span> criterion(outputs, labels)
</span></span><span style=display:flex><span>        <span style=color:#75715e># 反向傳播</span>
</span></span><span style=display:flex><span>        loss<span style=color:#f92672>.</span>backward() 
</span></span><span style=display:flex><span>        <span style=color:#75715e># 更新權重</span>
</span></span><span style=display:flex><span>        optimizer<span style=color:#f92672>.</span>step() 
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        <span style=color:#75715e># 顯示損失</span>
</span></span><span style=display:flex><span>        train_loop<span style=color:#f92672>.</span>set_postfix(loss<span style=color:#f92672>=</span><span style=color:#e6db74>f</span><span style=color:#e6db74>&#39;</span><span style=color:#e6db74>{</span>loss<span style=color:#f92672>.</span>item()<span style=color:#e6db74>:</span><span style=color:#e6db74>.4f</span><span style=color:#e6db74>}</span><span style=color:#e6db74>&#39;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># 轉換預測值 (argmax 獲取最高 Log-機率的索引)</span>
</span></span><span style=display:flex><span>        predicted <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>argmax(outputs, dim<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>) 
</span></span><span style=display:flex><span>        <span style=color:#75715e># 將預測直查詢相加次數</span>
</span></span><span style=display:flex><span>        total_correct <span style=color:#f92672>+=</span> (predicted <span style=color:#f92672>==</span> labels)<span style=color:#f92672>.</span>sum()<span style=color:#f92672>.</span>item()
</span></span><span style=display:flex><span>        <span style=color:#75715e># 加總損失</span>
</span></span><span style=display:flex><span>        total_loss <span style=color:#f92672>+=</span> loss<span style=color:#f92672>.</span>item() <span style=color:#f92672>*</span> inputs<span style=color:#f92672>.</span>size(<span style=color:#ae81ff>0</span>)
</span></span><span style=display:flex><span>        <span style=color:#75715e># 加總訓練資料數量</span>
</span></span><span style=display:flex><span>        total_count <span style=color:#f92672>+=</span> inputs<span style=color:#f92672>.</span>size(<span style=color:#ae81ff>0</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 訓練結果輸出</span>
</span></span><span style=display:flex><span>    train_loss_avg <span style=color:#f92672>=</span> total_loss <span style=color:#f92672>/</span> total_count
</span></span><span style=display:flex><span>    train_acc_avg <span style=color:#f92672>=</span> total_correct <span style=color:#f92672>/</span> total_count
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#39;Epoch </span><span style=color:#e6db74>{</span>epoch<span style=color:#f92672>+</span><span style=color:#ae81ff>1</span><span style=color:#e6db74>}</span><span style=color:#e6db74>/</span><span style=color:#e6db74>{</span>NUM_EPOCHS<span style=color:#e6db74>}</span><span style=color:#e6db74> - loss: </span><span style=color:#e6db74>{</span>train_loss_avg<span style=color:#e6db74>:</span><span style=color:#e6db74>.4f</span><span style=color:#e6db74>}</span><span style=color:#e6db74> - acc: </span><span style=color:#e6db74>{</span>train_acc_avg<span style=color:#e6db74>:</span><span style=color:#e6db74>.4f</span><span style=color:#e6db74>}</span><span style=color:#e6db74>&#39;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span><span style=color:#75715e># 切換到評估模式</span>
</span></span><span style=display:flex><span>model<span style=color:#f92672>.</span>eval()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>correct <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span>total <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span><span style=color:#75715e># 不計算梯度</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>with</span> torch<span style=color:#f92672>.</span>no_grad():
</span></span><span style=display:flex><span>    <span style=color:#75715e># 初始化損失和準確和數量</span>
</span></span><span style=display:flex><span>    total_loss, total_correct, total_count <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> inputs, labels <span style=color:#f92672>in</span> tqdm(valloader, desc<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;驗證 (Validation)&#34;</span>, unit<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;batch&#34;</span>): 
</span></span><span style=display:flex><span>        <span style=color:#75715e># 驗證集設定設備</span>
</span></span><span style=display:flex><span>        inputs, labels <span style=color:#f92672>=</span> inputs<span style=color:#f92672>.</span>to(device), labels<span style=color:#f92672>.</span>to(device) 
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        <span style=color:#75715e># 執行模型</span>
</span></span><span style=display:flex><span>        outputs <span style=color:#f92672>=</span> model(inputs)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># 取得損失</span>
</span></span><span style=display:flex><span>        loss <span style=color:#f92672>=</span> criterion(outputs, labels)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># 轉換預測值</span>
</span></span><span style=display:flex><span>        predicted <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>argmax(outputs, dim<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>) 
</span></span><span style=display:flex><span>        <span style=color:#75715e># 將預測直查詢相加次數</span>
</span></span><span style=display:flex><span>        total_correct <span style=color:#f92672>+=</span> (predicted <span style=color:#f92672>==</span> labels)<span style=color:#f92672>.</span>sum()<span style=color:#f92672>.</span>item()
</span></span><span style=display:flex><span>        <span style=color:#75715e># 加總損失</span>
</span></span><span style=display:flex><span>        total_loss <span style=color:#f92672>+=</span> loss<span style=color:#f92672>.</span>item() <span style=color:#f92672>*</span> inputs<span style=color:#f92672>.</span>size(<span style=color:#ae81ff>0</span>)
</span></span><span style=display:flex><span>        <span style=color:#75715e># 加總訓練資料數量</span>
</span></span><span style=display:flex><span>        total_count <span style=color:#f92672>+=</span> inputs<span style=color:#f92672>.</span>size(<span style=color:#ae81ff>0</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>&#39;=&#39;</span><span style=color:#f92672>*</span><span style=color:#ae81ff>50</span>)
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#39;驗證結果 - loss: </span><span style=color:#e6db74>{</span>total_loss <span style=color:#f92672>/</span> total_count<span style=color:#e6db74>:</span><span style=color:#e6db74>.4f</span><span style=color:#e6db74>}</span><span style=color:#e6db74> - acc: </span><span style=color:#e6db74>{</span>total_correct <span style=color:#f92672>/</span> total_count<span style=color:#e6db74>:</span><span style=color:#e6db74>.4f</span><span style=color:#e6db74>}</span><span style=color:#e6db74>&#39;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>&#39;=&#39;</span><span style=color:#f92672>*</span><span style=color:#ae81ff>50</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 初始化損失和準確和數量</span>
</span></span><span style=display:flex><span>    total_loss, total_correct, total_count <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> inputs, labels <span style=color:#f92672>in</span> tqdm(testloader, desc<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;最終測試 (Testing)&#34;</span>, unit<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;batch&#34;</span>): 
</span></span><span style=display:flex><span>        <span style=color:#75715e># 測試集設定設備</span>
</span></span><span style=display:flex><span>        inputs, labels <span style=color:#f92672>=</span> inputs<span style=color:#f92672>.</span>to(device), labels<span style=color:#f92672>.</span>to(device) 
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        <span style=color:#75715e># 執行模型</span>
</span></span><span style=display:flex><span>        outputs <span style=color:#f92672>=</span> model(inputs)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># 取得損失</span>
</span></span><span style=display:flex><span>        loss <span style=color:#f92672>=</span> criterion(outputs, labels)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># 轉換預測值</span>
</span></span><span style=display:flex><span>        predicted <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>argmax(outputs, dim<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>) 
</span></span><span style=display:flex><span>        <span style=color:#75715e># 將預測直查詢相加次數</span>
</span></span><span style=display:flex><span>        total_correct <span style=color:#f92672>+=</span> (predicted <span style=color:#f92672>==</span> labels)<span style=color:#f92672>.</span>sum()<span style=color:#f92672>.</span>item()
</span></span><span style=display:flex><span>        <span style=color:#75715e># 加總損失</span>
</span></span><span style=display:flex><span>        total_loss <span style=color:#f92672>+=</span> loss<span style=color:#f92672>.</span>item() <span style=color:#f92672>*</span> inputs<span style=color:#f92672>.</span>size(<span style=color:#ae81ff>0</span>)
</span></span><span style=display:flex><span>        <span style=color:#75715e># 加總訓練資料數量</span>
</span></span><span style=display:flex><span>        total_count <span style=color:#f92672>+=</span> inputs<span style=color:#f92672>.</span>size(<span style=color:#ae81ff>0</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>&#39;=&#39;</span><span style=color:#f92672>*</span><span style=color:#ae81ff>50</span>)
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#39;測試集結果 - loss: </span><span style=color:#e6db74>{</span>total_loss <span style=color:#f92672>/</span> total_count<span style=color:#e6db74>:</span><span style=color:#e6db74>.4f</span><span style=color:#e6db74>}</span><span style=color:#e6db74> - acc: </span><span style=color:#e6db74>{</span>total_correct <span style=color:#f92672>/</span> total_count<span style=color:#e6db74>:</span><span style=color:#e6db74>.4f</span><span style=color:#e6db74>}</span><span style=color:#e6db74>&#39;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 切換到訓練模式</span>
</span></span><span style=display:flex><span>model<span style=color:#f92672>.</span>train()
</span></span></code></pre></div><h3 id=alexnet>alexnet</h3><p>cnn的進化版</p><h4 id=縮減版>縮減版</h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py><span style=display:flex><span><span style=color:#f92672>import</span> torch
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> torch <span style=color:#f92672>import</span> nn, optim
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> torch.utils.data <span style=color:#f92672>import</span> TensorDataset, DataLoader, random_split
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> torchvision <span style=color:#f92672>import</span> datasets, transforms
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> tqdm <span style=color:#f92672>import</span> tqdm
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 使用顯卡或cpu執行</span>
</span></span><span style=display:flex><span>device <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>device(<span style=color:#e6db74>&#39;cuda&#39;</span> <span style=color:#66d9ef>if</span> torch<span style=color:#f92672>.</span>cuda<span style=color:#f92672>.</span>is_available() <span style=color:#66d9ef>else</span> <span style=color:#e6db74>&#39;cpu&#39;</span>)
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;使用的設備: </span><span style=color:#e6db74>{</span>device<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 將資料轉換</span>
</span></span><span style=display:flex><span>transform <span style=color:#f92672>=</span> transforms<span style=color:#f92672>.</span>Compose([
</span></span><span style=display:flex><span>    <span style=color:#75715e># 更改圖片大小</span>
</span></span><span style=display:flex><span>    transforms<span style=color:#f92672>.</span>Resize(<span style=color:#ae81ff>227</span>),
</span></span><span style=display:flex><span>    <span style=color:#75715e># 將資料轉換Tensor 格式</span>
</span></span><span style=display:flex><span>    transforms<span style=color:#f92672>.</span>PILToTensor(),
</span></span><span style=display:flex><span>    transforms<span style=color:#f92672>.</span>ConvertImageDtype(torch<span style=color:#f92672>.</span>float)
</span></span><span style=display:flex><span>])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 載入訓練集，載入位置，是否為訓練集，如果沒有就下載</span>
</span></span><span style=display:flex><span>trainset <span style=color:#f92672>=</span> datasets<span style=color:#f92672>.</span>CIFAR10(
</span></span><span style=display:flex><span>    root<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;./data&#39;</span>, 
</span></span><span style=display:flex><span>    train<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>, 
</span></span><span style=display:flex><span>    download<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>,
</span></span><span style=display:flex><span>    transform<span style=color:#f92672>=</span>transform
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span><span style=color:#75715e># 載入測試集，載入位置，是否為訓練集，如果沒有就下載</span>
</span></span><span style=display:flex><span>testset <span style=color:#f92672>=</span> datasets<span style=color:#f92672>.</span>CIFAR10(
</span></span><span style=display:flex><span>    root<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;./data&#39;</span>, 
</span></span><span style=display:flex><span>    train<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>, 
</span></span><span style=display:flex><span>    download<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>,
</span></span><span style=display:flex><span>    transform<span style=color:#f92672>=</span>transform
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 分割訓練集8:2分 (訓練集與驗證集)</span>
</span></span><span style=display:flex><span>train_size <span style=color:#f92672>=</span> int((<span style=color:#ae81ff>1</span> <span style=color:#f92672>-</span> <span style=color:#ae81ff>0.2</span>) <span style=color:#f92672>*</span> len(trainset))
</span></span><span style=display:flex><span>val_size <span style=color:#f92672>=</span> len(trainset) <span style=color:#f92672>-</span> train_size
</span></span><span style=display:flex><span>train_dataset, val_dataset <span style=color:#f92672>=</span> random_split(trainset, [train_size, val_size])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 資料集分群批</span>
</span></span><span style=display:flex><span>BATCH_SIZE <span style=color:#f92672>=</span> <span style=color:#ae81ff>64</span>
</span></span><span style=display:flex><span>trainloader <span style=color:#f92672>=</span> DataLoader(train_dataset, batch_size<span style=color:#f92672>=</span>BATCH_SIZE, shuffle<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span><span style=display:flex><span>valloader <span style=color:#f92672>=</span> DataLoader(val_dataset, batch_size<span style=color:#f92672>=</span>BATCH_SIZE, shuffle<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>)
</span></span><span style=display:flex><span>testloader <span style=color:#f92672>=</span> DataLoader(testset, batch_size<span style=color:#f92672>=</span>BATCH_SIZE, shuffle<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>alexnet</span>(nn<span style=color:#f92672>.</span>Module):
</span></span><span style=display:flex><span>    <span style=color:#75715e># 這裡的初始化用於定義所有的層</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> __init__(self, num_classes<span style=color:#f92672>=</span><span style=color:#ae81ff>10</span>):
</span></span><span style=display:flex><span>        super(alexnet, self)<span style=color:#f92672>.</span>__init__()
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        <span style=color:#75715e># 第一層：卷積層與池化層</span>
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>features_shared <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Sequential(
</span></span><span style=display:flex><span>            <span style=color:#75715e># 找出圖片特徵，在圖片中找出96個11x11大小範圍內的特徵，以間4x4位移，並將小於0值為0，輸入為3層</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>96</span>, (<span style=color:#ae81ff>11</span>, <span style=color:#ae81ff>11</span>), stride<span style=color:#f92672>=</span>(<span style=color:#ae81ff>4</span>, <span style=color:#ae81ff>4</span>)), nn<span style=color:#f92672>.</span>ReLU(),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 輔助層 將資料逕行整理以便後續分析</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>BatchNorm2d(<span style=color:#ae81ff>96</span>),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 池化層 減少值數量找到最大值，以3x3大小找並以2x2位移</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>MaxPool2d(kernel_size<span style=color:#f92672>=</span>(<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>3</span>), stride<span style=color:#f92672>=</span>(<span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>2</span>)), 
</span></span><span style=display:flex><span>        )
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        <span style=color:#75715e># ------------------ Path A 結構 ------------------</span>
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>path_a_features <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Sequential(
</span></span><span style=display:flex><span>            <span style=color:#75715e># 卷積層 找出圖片特徵，在圖片中找出256個5x5大小範圍內的特徵，並將小於0值為0,並在周圍補0，輸入為96層</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>96</span>, <span style=color:#ae81ff>256</span>, (<span style=color:#ae81ff>5</span>, <span style=color:#ae81ff>5</span>), padding<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>), nn<span style=color:#f92672>.</span>ReLU(),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 輔助層 將資料逕行整理以便後續分析</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>BatchNorm2d(<span style=color:#ae81ff>256</span>),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 池化層 減少值數量找到最大值，以3x3大小找並以2x2位移</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>MaxPool2d(kernel_size<span style=color:#f92672>=</span>(<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>3</span>), stride<span style=color:#f92672>=</span>(<span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>2</span>)), 
</span></span><span style=display:flex><span>            <span style=color:#75715e># 卷積層 找出圖片特徵，在圖片中找出384個3x3大小範圍內的特徵，並將小於0值為0,並在周圍補0，輸入為256層</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>256</span>, <span style=color:#ae81ff>384</span>, (<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>3</span>), padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>), nn<span style=color:#f92672>.</span>ReLU(),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 輔助層 將資料逕行整理以便後續分析</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>BatchNorm2d(<span style=color:#ae81ff>384</span>),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 卷積層 找出圖片特徵，在圖片中找出384個3x3大小範圍內的特徵，並將小於0值為0,並在周圍補0，輸入為384層</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>384</span>, <span style=color:#ae81ff>384</span>, (<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>3</span>), padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>), nn<span style=color:#f92672>.</span>ReLU(),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 輔助層 將資料逕行整理以便後續分析</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>BatchNorm2d(<span style=color:#ae81ff>384</span>),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 卷積層 找出圖片特徵，在圖片中找出256個3x3大小範圍內的特徵，並將小於0值為0,並在周圍補0，輸入為384層</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>384</span>, <span style=color:#ae81ff>256</span>, (<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>3</span>), padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>), nn<span style=color:#f92672>.</span>ReLU(),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 輔助層 將資料逕行整理以便後續分析</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>BatchNorm2d(<span style=color:#ae81ff>256</span>),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 池化層 減少值數量找到最大值，以3x3大小找並以2x2位移</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>MaxPool2d(kernel_size<span style=color:#f92672>=</span>(<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>3</span>), stride<span style=color:#f92672>=</span>(<span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>2</span>)),
</span></span><span style=display:flex><span>        )
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># ------------------ Path B 結構 (與 Path A 相同) ------------------</span>
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>path_b_features <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Sequential(
</span></span><span style=display:flex><span>            <span style=color:#75715e># 卷積層 找出圖片特徵，在圖片中找出256個5x5大小範圍內的特徵，並將小於0值為0,並在周圍補0，輸入為96層</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>96</span>, <span style=color:#ae81ff>256</span>, (<span style=color:#ae81ff>5</span>, <span style=color:#ae81ff>5</span>), padding<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>), nn<span style=color:#f92672>.</span>ReLU(),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 輔助層 將資料逕行整理以便後續分析</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>BatchNorm2d(<span style=color:#ae81ff>256</span>),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 池化層 減少值數量找到最大值，以3x3大小找並以2x2位移</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>MaxPool2d(kernel_size<span style=color:#f92672>=</span>(<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>3</span>), stride<span style=color:#f92672>=</span>(<span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>2</span>)), 
</span></span><span style=display:flex><span>            <span style=color:#75715e># 卷積層 找出圖片特徵，在圖片中找出384個3x3大小範圍內的特徵，並將小於0值為0,並在周圍補0，輸入為256層</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>256</span>, <span style=color:#ae81ff>384</span>, (<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>3</span>), padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>), nn<span style=color:#f92672>.</span>ReLU(),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 輔助層 將資料逕行整理以便後續分析</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>BatchNorm2d(<span style=color:#ae81ff>384</span>),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 卷積層 找出圖片特徵，在圖片中找出384個3x3大小範圍內的特徵，並將小於0值為0,並在周圍補0，輸入為384層</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>384</span>, <span style=color:#ae81ff>384</span>, (<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>3</span>), padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>), nn<span style=color:#f92672>.</span>ReLU(),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 輔助層 將資料逕行整理以便後續分析</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>BatchNorm2d(<span style=color:#ae81ff>384</span>),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 卷積層 找出圖片特徵，在圖片中找出256個3x3大小範圍內的特徵，並將小於0值為0,並在周圍補0，輸入為384層</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>384</span>, <span style=color:#ae81ff>256</span>, (<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>3</span>), padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>), nn<span style=color:#f92672>.</span>ReLU(),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 輔助層 將資料逕行整理以便後續分析</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>BatchNorm2d(<span style=color:#ae81ff>256</span>),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 池化層 減少值數量找到最大值，以3x3大小找並以2x2位移</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>MaxPool2d(kernel_size<span style=color:#f92672>=</span>(<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>3</span>), stride<span style=color:#f92672>=</span>(<span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>2</span>)),
</span></span><span style=display:flex><span>        )
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># ------------------ 分類器 (Classification) ------------------</span>
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>classifier <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Sequential(
</span></span><span style=display:flex><span>            <span style=color:#75715e># 攤平層 將二維轉換一維</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Flatten(), <span style=color:#75715e># 這裡在 forward 中手動處理</span>
</span></span><span style=display:flex><span>            
</span></span><span style=display:flex><span>            <span style=color:#75715e># 全連接層 將攤平層整理出4096的輸出</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Linear(<span style=color:#ae81ff>512</span> <span style=color:#f92672>*</span> <span style=color:#ae81ff>6</span> <span style=color:#f92672>*</span> <span style=color:#ae81ff>6</span>, <span style=color:#ae81ff>4096</span>), nn<span style=color:#f92672>.</span>ReLU(),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 0.5的機率隨機關閉輸出</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Dropout(<span style=color:#ae81ff>0.5</span>),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 全連接層 將攤平層整理出4096的輸出</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Linear(<span style=color:#ae81ff>4096</span>, <span style=color:#ae81ff>4096</span>), nn<span style=color:#f92672>.</span>ReLU(),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 0.5的機率隨機關閉輸出</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Dropout(<span style=color:#ae81ff>0.5</span>),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 全連接層 最後整理輸出訓練集所分類的10個</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Linear(<span style=color:#ae81ff>4096</span>, num_classes)
</span></span><span style=display:flex><span>        )
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 這裡的 forward 函式定義數據如何流經網路</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>forward</span>(self, x):
</span></span><span style=display:flex><span>        <span style=color:#75715e># 第一層：卷積層與池化層</span>
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>features_shared(x)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># 分成兩個獨立的支流</span>
</span></span><span style=display:flex><span>        path_a <span style=color:#f92672>=</span> x
</span></span><span style=display:flex><span>        path_b <span style=color:#f92672>=</span> x
</span></span><span style=display:flex><span>        <span style=color:#75715e># 第一條支流 (Path A)</span>
</span></span><span style=display:flex><span>        path_a <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>path_a_features(path_a)
</span></span><span style=display:flex><span>        <span style=color:#75715e># 第二條支流 (Path B)</span>
</span></span><span style=display:flex><span>        path_b <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>path_b_features(path_b)
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        <span style=color:#75715e># 合併兩條支流</span>
</span></span><span style=display:flex><span>        merged <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>cat([path_a, path_b], dim<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        <span style=color:#75715e># 分類器 (Classification)</span>
</span></span><span style=display:flex><span>        outputs <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>classifier(merged)
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> outputs
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 設定損失</span>
</span></span><span style=display:flex><span>criterion <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>CrossEntropyLoss()
</span></span><span style=display:flex><span><span style=color:#75715e># 設定模型</span>
</span></span><span style=display:flex><span>model <span style=color:#f92672>=</span> alexnet(num_classes<span style=color:#f92672>=</span><span style=color:#ae81ff>10</span>)<span style=color:#f92672>.</span>to(device)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 設定優化</span>
</span></span><span style=display:flex><span>optimizer <span style=color:#f92672>=</span> optim<span style=color:#f92672>.</span>Adam(model<span style=color:#f92672>.</span>parameters(), lr<span style=color:#f92672>=</span><span style=color:#ae81ff>0.001</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>NUM_EPOCHS <span style=color:#f92672>=</span> <span style=color:#ae81ff>1</span> 
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 設定訓練次數</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> epoch <span style=color:#f92672>in</span> range(NUM_EPOCHS):
</span></span><span style=display:flex><span>    <span style=color:#75715e># 初始化損失和準確和數量</span>
</span></span><span style=display:flex><span>    total_loss, total_correct, total_count <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#75715e># 設定進度條，將訓練集載入</span>
</span></span><span style=display:flex><span>    train_loop <span style=color:#f92672>=</span> tqdm(
</span></span><span style=display:flex><span>        trainloader, 
</span></span><span style=display:flex><span>        desc<span style=color:#f92672>=</span><span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Epoch </span><span style=color:#e6db74>{</span>epoch <span style=color:#f92672>+</span> <span style=color:#ae81ff>1</span><span style=color:#e6db74>}</span><span style=color:#e6db74>/</span><span style=color:#e6db74>{</span><span style=color:#ae81ff>1</span><span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>, 
</span></span><span style=display:flex><span>        unit<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;batch&#34;</span>,
</span></span><span style=display:flex><span>        leave<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>
</span></span><span style=display:flex><span>    )
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#75715e># 使用進度調</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> inputs, labels <span style=color:#f92672>in</span> train_loop:
</span></span><span style=display:flex><span>        <span style=color:#75715e># 訓練集設定設備</span>
</span></span><span style=display:flex><span>        inputs, labels <span style=color:#f92672>=</span> inputs<span style=color:#f92672>.</span>to(device), labels<span style=color:#f92672>.</span>to(device)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># 梯度歸零，因為pytocrh的梯度不會規零，主要原因是批次訓練</span>
</span></span><span style=display:flex><span>        optimizer<span style=color:#f92672>.</span>zero_grad() 
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        <span style=color:#75715e># 執行模型</span>
</span></span><span style=display:flex><span>        outputs <span style=color:#f92672>=</span> model(inputs)
</span></span><span style=display:flex><span>        <span style=color:#75715e># 取得損失</span>
</span></span><span style=display:flex><span>        loss <span style=color:#f92672>=</span> criterion(outputs, labels)
</span></span><span style=display:flex><span>        <span style=color:#75715e># 反向傳播</span>
</span></span><span style=display:flex><span>        loss<span style=color:#f92672>.</span>backward() 
</span></span><span style=display:flex><span>        <span style=color:#75715e># 更新權重</span>
</span></span><span style=display:flex><span>        optimizer<span style=color:#f92672>.</span>step() 
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        <span style=color:#75715e># 顯示損失</span>
</span></span><span style=display:flex><span>        train_loop<span style=color:#f92672>.</span>set_postfix(loss<span style=color:#f92672>=</span><span style=color:#e6db74>f</span><span style=color:#e6db74>&#39;</span><span style=color:#e6db74>{</span>loss<span style=color:#f92672>.</span>item()<span style=color:#e6db74>:</span><span style=color:#e6db74>.4f</span><span style=color:#e6db74>}</span><span style=color:#e6db74>&#39;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># 轉換預測值 (argmax 獲取最高 Log-機率的索引)</span>
</span></span><span style=display:flex><span>        predicted <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>argmax(outputs, dim<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>) 
</span></span><span style=display:flex><span>        <span style=color:#75715e># 將預測直查詢相加次數</span>
</span></span><span style=display:flex><span>        total_correct <span style=color:#f92672>+=</span> (predicted <span style=color:#f92672>==</span> labels)<span style=color:#f92672>.</span>sum()<span style=color:#f92672>.</span>item()
</span></span><span style=display:flex><span>        <span style=color:#75715e># 加總損失</span>
</span></span><span style=display:flex><span>        total_loss <span style=color:#f92672>+=</span> loss<span style=color:#f92672>.</span>item() <span style=color:#f92672>*</span> inputs<span style=color:#f92672>.</span>size(<span style=color:#ae81ff>0</span>)
</span></span><span style=display:flex><span>        <span style=color:#75715e># 加總訓練資料數量</span>
</span></span><span style=display:flex><span>        total_count <span style=color:#f92672>+=</span> inputs<span style=color:#f92672>.</span>size(<span style=color:#ae81ff>0</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 訓練結果輸出</span>
</span></span><span style=display:flex><span>    train_loss_avg <span style=color:#f92672>=</span> total_loss <span style=color:#f92672>/</span> total_count
</span></span><span style=display:flex><span>    train_acc_avg <span style=color:#f92672>=</span> total_correct <span style=color:#f92672>/</span> total_count
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#39;Epoch </span><span style=color:#e6db74>{</span>epoch<span style=color:#f92672>+</span><span style=color:#ae81ff>1</span><span style=color:#e6db74>}</span><span style=color:#e6db74>/</span><span style=color:#e6db74>{</span>NUM_EPOCHS<span style=color:#e6db74>}</span><span style=color:#e6db74> - loss: </span><span style=color:#e6db74>{</span>train_loss_avg<span style=color:#e6db74>:</span><span style=color:#e6db74>.4f</span><span style=color:#e6db74>}</span><span style=color:#e6db74> - acc: </span><span style=color:#e6db74>{</span>train_acc_avg<span style=color:#e6db74>:</span><span style=color:#e6db74>.4f</span><span style=color:#e6db74>}</span><span style=color:#e6db74>&#39;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span><span style=color:#75715e># 切換到評估模式</span>
</span></span><span style=display:flex><span>model<span style=color:#f92672>.</span>eval()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>correct <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span>total <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span><span style=color:#75715e># 不計算梯度</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>with</span> torch<span style=color:#f92672>.</span>no_grad():
</span></span><span style=display:flex><span>    <span style=color:#75715e># 初始化損失和準確和數量</span>
</span></span><span style=display:flex><span>    total_loss, total_correct, total_count <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> inputs, labels <span style=color:#f92672>in</span> tqdm(valloader, desc<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;驗證 (Validation)&#34;</span>, unit<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;batch&#34;</span>): 
</span></span><span style=display:flex><span>        <span style=color:#75715e># 驗證集設定設備</span>
</span></span><span style=display:flex><span>        inputs, labels <span style=color:#f92672>=</span> inputs<span style=color:#f92672>.</span>to(device), labels<span style=color:#f92672>.</span>to(device) 
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        <span style=color:#75715e># 執行模型</span>
</span></span><span style=display:flex><span>        outputs <span style=color:#f92672>=</span> model(inputs)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># 取得損失</span>
</span></span><span style=display:flex><span>        loss <span style=color:#f92672>=</span> criterion(outputs, labels)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># 轉換預測值</span>
</span></span><span style=display:flex><span>        predicted <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>argmax(outputs, dim<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>) 
</span></span><span style=display:flex><span>        <span style=color:#75715e># 將預測直查詢相加次數</span>
</span></span><span style=display:flex><span>        total_correct <span style=color:#f92672>+=</span> (predicted <span style=color:#f92672>==</span> labels)<span style=color:#f92672>.</span>sum()<span style=color:#f92672>.</span>item()
</span></span><span style=display:flex><span>        <span style=color:#75715e># 加總損失</span>
</span></span><span style=display:flex><span>        total_loss <span style=color:#f92672>+=</span> loss<span style=color:#f92672>.</span>item() <span style=color:#f92672>*</span> inputs<span style=color:#f92672>.</span>size(<span style=color:#ae81ff>0</span>)
</span></span><span style=display:flex><span>        <span style=color:#75715e># 加總訓練資料數量</span>
</span></span><span style=display:flex><span>        total_count <span style=color:#f92672>+=</span> inputs<span style=color:#f92672>.</span>size(<span style=color:#ae81ff>0</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>&#39;=&#39;</span><span style=color:#f92672>*</span><span style=color:#ae81ff>50</span>)
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#39;驗證結果 - loss: </span><span style=color:#e6db74>{</span>total_loss <span style=color:#f92672>/</span> total_count<span style=color:#e6db74>:</span><span style=color:#e6db74>.4f</span><span style=color:#e6db74>}</span><span style=color:#e6db74> - acc: </span><span style=color:#e6db74>{</span>total_correct <span style=color:#f92672>/</span> total_count<span style=color:#e6db74>:</span><span style=color:#e6db74>.4f</span><span style=color:#e6db74>}</span><span style=color:#e6db74>&#39;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>&#39;=&#39;</span><span style=color:#f92672>*</span><span style=color:#ae81ff>50</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 初始化損失和準確和數量</span>
</span></span><span style=display:flex><span>    total_loss, total_correct, total_count <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> inputs, labels <span style=color:#f92672>in</span> tqdm(testloader, desc<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;最終測試 (Testing)&#34;</span>, unit<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;batch&#34;</span>): 
</span></span><span style=display:flex><span>        <span style=color:#75715e># 測試集設定設備</span>
</span></span><span style=display:flex><span>        inputs, labels <span style=color:#f92672>=</span> inputs<span style=color:#f92672>.</span>to(device), labels<span style=color:#f92672>.</span>to(device) 
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        <span style=color:#75715e># 執行模型</span>
</span></span><span style=display:flex><span>        outputs <span style=color:#f92672>=</span> model(inputs)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># 取得損失</span>
</span></span><span style=display:flex><span>        loss <span style=color:#f92672>=</span> criterion(outputs, labels)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># 轉換預測值</span>
</span></span><span style=display:flex><span>        predicted <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>argmax(outputs, dim<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>) 
</span></span><span style=display:flex><span>        <span style=color:#75715e># 將預測直查詢相加次數</span>
</span></span><span style=display:flex><span>        total_correct <span style=color:#f92672>+=</span> (predicted <span style=color:#f92672>==</span> labels)<span style=color:#f92672>.</span>sum()<span style=color:#f92672>.</span>item()
</span></span><span style=display:flex><span>        <span style=color:#75715e># 加總損失</span>
</span></span><span style=display:flex><span>        total_loss <span style=color:#f92672>+=</span> loss<span style=color:#f92672>.</span>item() <span style=color:#f92672>*</span> inputs<span style=color:#f92672>.</span>size(<span style=color:#ae81ff>0</span>)
</span></span><span style=display:flex><span>        <span style=color:#75715e># 加總訓練資料數量</span>
</span></span><span style=display:flex><span>        total_count <span style=color:#f92672>+=</span> inputs<span style=color:#f92672>.</span>size(<span style=color:#ae81ff>0</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>&#39;=&#39;</span><span style=color:#f92672>*</span><span style=color:#ae81ff>50</span>)
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#39;測試集結果 - loss: </span><span style=color:#e6db74>{</span>total_loss <span style=color:#f92672>/</span> total_count<span style=color:#e6db74>:</span><span style=color:#e6db74>.4f</span><span style=color:#e6db74>}</span><span style=color:#e6db74> - acc: </span><span style=color:#e6db74>{</span>total_correct <span style=color:#f92672>/</span> total_count<span style=color:#e6db74>:</span><span style=color:#e6db74>.4f</span><span style=color:#e6db74>}</span><span style=color:#e6db74>&#39;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 切換到訓練模式</span>
</span></span><span style=display:flex><span>model<span style=color:#f92672>.</span>train()
</span></span></code></pre></div><h4 id=完整版>完整版</h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py><span style=display:flex><span><span style=color:#f92672>import</span> torch
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> torch <span style=color:#f92672>import</span> nn, optim
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> torch.utils.data <span style=color:#f92672>import</span> DataLoader
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> torchvision <span style=color:#f92672>import</span> datasets, transforms
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> tqdm <span style=color:#f92672>import</span> tqdm
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 鎖定設備為 CPU</span>
</span></span><span style=display:flex><span>device <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>device(<span style=color:#e6db74>&#34;cpu&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 將資料轉換</span>
</span></span><span style=display:flex><span>transform <span style=color:#f92672>=</span> transforms<span style=color:#f92672>.</span>Compose([
</span></span><span style=display:flex><span>    <span style=color:#75715e># 更改圖片大小</span>
</span></span><span style=display:flex><span>    transforms<span style=color:#f92672>.</span>Resize(<span style=color:#ae81ff>227</span>),
</span></span><span style=display:flex><span>    <span style=color:#75715e># 將資料轉換Tensor 格式</span>
</span></span><span style=display:flex><span>    transforms<span style=color:#f92672>.</span>PILToTensor(),
</span></span><span style=display:flex><span>    transforms<span style=color:#f92672>.</span>ConvertImageDtype(torch<span style=color:#f92672>.</span>float)
</span></span><span style=display:flex><span>])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 載入訓練集，載入位置，是否為訓練集，如果沒有就下載</span>
</span></span><span style=display:flex><span>trainset <span style=color:#f92672>=</span> datasets<span style=color:#f92672>.</span>CIFAR10(
</span></span><span style=display:flex><span>    root<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;./data&#39;</span>, 
</span></span><span style=display:flex><span>    train<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>, 
</span></span><span style=display:flex><span>    download<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>,
</span></span><span style=display:flex><span>    transform<span style=color:#f92672>=</span>transform
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span><span style=color:#75715e># 載入測試集，載入位置，是否為訓練集，如果沒有就下載</span>
</span></span><span style=display:flex><span>testset <span style=color:#f92672>=</span> datasets<span style=color:#f92672>.</span>CIFAR10(
</span></span><span style=display:flex><span>    root<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;./data&#39;</span>, 
</span></span><span style=display:flex><span>    train<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>, 
</span></span><span style=display:flex><span>    download<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>,
</span></span><span style=display:flex><span>    transform<span style=color:#f92672>=</span>transform
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 將資料分批</span>
</span></span><span style=display:flex><span>trainloader <span style=color:#f92672>=</span> DataLoader(trainset, batch_size<span style=color:#f92672>=</span><span style=color:#ae81ff>64</span>, shuffle<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span><span style=display:flex><span>testloader <span style=color:#f92672>=</span> DataLoader(testset, batch_size<span style=color:#f92672>=</span><span style=color:#ae81ff>64</span>, shuffle<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>model</span>(nn<span style=color:#f92672>.</span>Module):
</span></span><span style=display:flex><span>    <span style=color:#75715e># 這裡的初始化用於定義所有的層</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> __init__(self, num_classes<span style=color:#f92672>=</span><span style=color:#ae81ff>10</span>):
</span></span><span style=display:flex><span>        super(model, self)<span style=color:#f92672>.</span>__init__()
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        <span style=color:#75715e># 第一層：卷積層與池化層</span>
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>features_shared <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Sequential(
</span></span><span style=display:flex><span>            <span style=color:#75715e># 找出圖片特徵，在圖片中找出96個11x11大小範圍內的特徵，以間4x4位移，並將小於0值為0，輸入為3層</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>96</span>, (<span style=color:#ae81ff>11</span>, <span style=color:#ae81ff>11</span>), stride<span style=color:#f92672>=</span>(<span style=color:#ae81ff>4</span>, <span style=color:#ae81ff>4</span>)), nn<span style=color:#f92672>.</span>ReLU(),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 輔助層 將資料逕行整理以便後續分析</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>BatchNorm2d(<span style=color:#ae81ff>96</span>),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 池化層 減少值數量找到最大值，以3x3大小找並以2x2位移</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>MaxPool2d(kernel_size<span style=color:#f92672>=</span>(<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>3</span>), stride<span style=color:#f92672>=</span>(<span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>2</span>)), 
</span></span><span style=display:flex><span>        )
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        <span style=color:#75715e># ------------------ Path A 結構 ------------------</span>
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>path_a_features <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Sequential(
</span></span><span style=display:flex><span>            <span style=color:#75715e># 卷積層 找出圖片特徵，在圖片中找出256個5x5大小範圍內的特徵，並將小於0值為0,並在周圍補0，輸入為96層</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>96</span>, <span style=color:#ae81ff>256</span>, (<span style=color:#ae81ff>5</span>, <span style=color:#ae81ff>5</span>), padding<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>), nn<span style=color:#f92672>.</span>ReLU(),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 輔助層 將資料逕行整理以便後續分析</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>BatchNorm2d(<span style=color:#ae81ff>256</span>),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 池化層 減少值數量找到最大值，以3x3大小找並以2x2位移</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>MaxPool2d(kernel_size<span style=color:#f92672>=</span>(<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>3</span>), stride<span style=color:#f92672>=</span>(<span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>2</span>)), 
</span></span><span style=display:flex><span>            <span style=color:#75715e># 卷積層 找出圖片特徵，在圖片中找出384個3x3大小範圍內的特徵，並將小於0值為0,並在周圍補0，輸入為256層</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>256</span>, <span style=color:#ae81ff>384</span>, (<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>3</span>), padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>), nn<span style=color:#f92672>.</span>ReLU(),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 輔助層 將資料逕行整理以便後續分析</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>BatchNorm2d(<span style=color:#ae81ff>384</span>),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 卷積層 找出圖片特徵，在圖片中找出384個3x3大小範圍內的特徵，並將小於0值為0,並在周圍補0，輸入為384層</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>384</span>, <span style=color:#ae81ff>384</span>, (<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>3</span>), padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>), nn<span style=color:#f92672>.</span>ReLU(),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 輔助層 將資料逕行整理以便後續分析</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>BatchNorm2d(<span style=color:#ae81ff>384</span>),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 卷積層 找出圖片特徵，在圖片中找出256個3x3大小範圍內的特徵，並將小於0值為0,並在周圍補0，輸入為384層</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>384</span>, <span style=color:#ae81ff>256</span>, (<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>3</span>), padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>), nn<span style=color:#f92672>.</span>ReLU(),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 輔助層 將資料逕行整理以便後續分析</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>BatchNorm2d(<span style=color:#ae81ff>256</span>),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 池化層 減少值數量找到最大值，以3x3大小找並以2x2位移</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>MaxPool2d(kernel_size<span style=color:#f92672>=</span>(<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>3</span>), stride<span style=color:#f92672>=</span>(<span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>2</span>)),
</span></span><span style=display:flex><span>        )
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># ------------------ Path B 結構 (與 Path A 相同) ------------------</span>
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>path_b_features <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Sequential(
</span></span><span style=display:flex><span>            <span style=color:#75715e># 卷積層 找出圖片特徵，在圖片中找出256個5x5大小範圍內的特徵，並將小於0值為0,並在周圍補0，輸入為96層</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>96</span>, <span style=color:#ae81ff>256</span>, (<span style=color:#ae81ff>5</span>, <span style=color:#ae81ff>5</span>), padding<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>), nn<span style=color:#f92672>.</span>ReLU(),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 輔助層 將資料逕行整理以便後續分析</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>BatchNorm2d(<span style=color:#ae81ff>256</span>),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 池化層 減少值數量找到最大值，以3x3大小找並以2x2位移</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>MaxPool2d(kernel_size<span style=color:#f92672>=</span>(<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>3</span>), stride<span style=color:#f92672>=</span>(<span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>2</span>)), 
</span></span><span style=display:flex><span>            <span style=color:#75715e># 卷積層 找出圖片特徵，在圖片中找出384個3x3大小範圍內的特徵，並將小於0值為0,並在周圍補0，輸入為256層</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>256</span>, <span style=color:#ae81ff>384</span>, (<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>3</span>), padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>), nn<span style=color:#f92672>.</span>ReLU(),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 輔助層 將資料逕行整理以便後續分析</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>BatchNorm2d(<span style=color:#ae81ff>384</span>),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 卷積層 找出圖片特徵，在圖片中找出384個3x3大小範圍內的特徵，並將小於0值為0,並在周圍補0，輸入為384層</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>384</span>, <span style=color:#ae81ff>384</span>, (<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>3</span>), padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>), nn<span style=color:#f92672>.</span>ReLU(),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 輔助層 將資料逕行整理以便後續分析</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>BatchNorm2d(<span style=color:#ae81ff>384</span>),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 卷積層 找出圖片特徵，在圖片中找出256個3x3大小範圍內的特徵，並將小於0值為0,並在周圍補0，輸入為384層</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>384</span>, <span style=color:#ae81ff>256</span>, (<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>3</span>), padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>), nn<span style=color:#f92672>.</span>ReLU(),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 輔助層 將資料逕行整理以便後續分析</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>BatchNorm2d(<span style=color:#ae81ff>256</span>),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 池化層 減少值數量找到最大值，以3x3大小找並以2x2位移</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>MaxPool2d(kernel_size<span style=color:#f92672>=</span>(<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>3</span>), stride<span style=color:#f92672>=</span>(<span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>2</span>)),
</span></span><span style=display:flex><span>        )
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># ------------------ 分類器 (Classification) ------------------</span>
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>classifier <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Sequential(
</span></span><span style=display:flex><span>            <span style=color:#75715e># 攤平層 將二維轉換一維</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Flatten(), <span style=color:#75715e># 這裡在 forward 中手動處理</span>
</span></span><span style=display:flex><span>            
</span></span><span style=display:flex><span>            <span style=color:#75715e># 全連接層 將攤平層整理出4096的輸出</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Linear(<span style=color:#ae81ff>512</span> <span style=color:#f92672>*</span> <span style=color:#ae81ff>6</span> <span style=color:#f92672>*</span> <span style=color:#ae81ff>6</span>, <span style=color:#ae81ff>4096</span>), nn<span style=color:#f92672>.</span>ReLU(),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 0.5的機率隨機關閉輸出</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Dropout(<span style=color:#ae81ff>0.5</span>),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 全連接層 將攤平層整理出4096的輸出</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Linear(<span style=color:#ae81ff>4096</span>, <span style=color:#ae81ff>4096</span>), nn<span style=color:#f92672>.</span>ReLU(),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 0.5的機率隨機關閉輸出</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Dropout(<span style=color:#ae81ff>0.5</span>),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 全連接層 最後整理輸出訓練集所分類的10個</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Linear(<span style=color:#ae81ff>4096</span>, num_classes),
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Softmax(dim<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>        )
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 這裡的 forward 函式定義數據如何流經網路</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>forward</span>(self, x):
</span></span><span style=display:flex><span>        <span style=color:#75715e># 第一層：卷積層與池化層</span>
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>features_shared(x)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># 分成兩個獨立的支流</span>
</span></span><span style=display:flex><span>        path_a <span style=color:#f92672>=</span> x
</span></span><span style=display:flex><span>        path_b <span style=color:#f92672>=</span> x
</span></span><span style=display:flex><span>        <span style=color:#75715e># 第一條支流 (Path A)</span>
</span></span><span style=display:flex><span>        path_a <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>path_a_features(path_a)
</span></span><span style=display:flex><span>        <span style=color:#75715e># 第二條支流 (Path B)</span>
</span></span><span style=display:flex><span>        path_b <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>path_b_features(path_b)
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        <span style=color:#75715e># 合併兩條支流</span>
</span></span><span style=display:flex><span>        merged <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>cat([path_a, path_b], dim<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        <span style=color:#75715e># 分類器 (Classification)</span>
</span></span><span style=display:flex><span>        outputs <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>classifier(merged)
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> outputs
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 設定損失</span>
</span></span><span style=display:flex><span>criterion <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>NLLLoss()
</span></span><span style=display:flex><span><span style=color:#75715e># 設定模型</span>
</span></span><span style=display:flex><span>net <span style=color:#f92672>=</span> model(num_classes<span style=color:#f92672>=</span><span style=color:#ae81ff>10</span>)<span style=color:#f92672>.</span>to(device)
</span></span><span style=display:flex><span><span style=color:#75715e># 設定優化</span>
</span></span><span style=display:flex><span>optimizer <span style=color:#f92672>=</span> optim<span style=color:#f92672>.</span>Adam(net<span style=color:#f92672>.</span>parameters(), lr<span style=color:#f92672>=</span><span style=color:#ae81ff>0.001</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 設定訓練次數</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> epoch <span style=color:#f92672>in</span> range(<span style=color:#ae81ff>1</span>):
</span></span><span style=display:flex><span>    <span style=color:#75715e># 初始化損失</span>
</span></span><span style=display:flex><span>    running_loss <span style=color:#f92672>=</span> <span style=color:#ae81ff>0.0</span>
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#75715e># 設定進度條，將訓練集載入</span>
</span></span><span style=display:flex><span>    train_loop <span style=color:#f92672>=</span> tqdm(
</span></span><span style=display:flex><span>        trainloader, 
</span></span><span style=display:flex><span>        desc<span style=color:#f92672>=</span><span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Epoch </span><span style=color:#e6db74>{</span>epoch <span style=color:#f92672>+</span> <span style=color:#ae81ff>1</span><span style=color:#e6db74>}</span><span style=color:#e6db74>/</span><span style=color:#e6db74>{</span><span style=color:#ae81ff>1</span><span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>, 
</span></span><span style=display:flex><span>        unit<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;batch&#34;</span>,
</span></span><span style=display:flex><span>        leave<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>
</span></span><span style=display:flex><span>    )
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#75715e># 使用進度調</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> inputs, labels <span style=color:#f92672>in</span> train_loop:
</span></span><span style=display:flex><span>        <span style=color:#75715e># 訓練集設定設備</span>
</span></span><span style=display:flex><span>        inputs, labels <span style=color:#f92672>=</span> inputs<span style=color:#f92672>.</span>to(device), labels<span style=color:#f92672>.</span>to(device)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># 梯度歸零，因為pytocrh的梯度不會規零，主要原因是批次訓練</span>
</span></span><span style=display:flex><span>        optimizer<span style=color:#f92672>.</span>zero_grad() 
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        <span style=color:#75715e># 執行模型</span>
</span></span><span style=display:flex><span>        outputs <span style=color:#f92672>=</span> net(inputs)
</span></span><span style=display:flex><span>        <span style=color:#75715e># 取得損失</span>
</span></span><span style=display:flex><span>        loss <span style=color:#f92672>=</span> criterion(outputs, labels)
</span></span><span style=display:flex><span>        <span style=color:#75715e># 反向傳播</span>
</span></span><span style=display:flex><span>        loss<span style=color:#f92672>.</span>backward() 
</span></span><span style=display:flex><span>        <span style=color:#75715e># 更新權重</span>
</span></span><span style=display:flex><span>        optimizer<span style=color:#f92672>.</span>step() 
</span></span><span style=display:flex><span>        <span style=color:#75715e># 損失加總</span>
</span></span><span style=display:flex><span>        running_loss <span style=color:#f92672>+=</span> loss<span style=color:#f92672>.</span>item() <span style=color:#f92672>*</span> inputs<span style=color:#f92672>.</span>size(<span style=color:#ae81ff>0</span>) 
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        <span style=color:#75715e># 顯示損失</span>
</span></span><span style=display:flex><span>        train_loop<span style=color:#f92672>.</span>set_postfix(loss<span style=color:#f92672>=</span><span style=color:#e6db74>f</span><span style=color:#e6db74>&#39;</span><span style=color:#e6db74>{</span>loss<span style=color:#f92672>.</span>item()<span style=color:#e6db74>:</span><span style=color:#e6db74>.4f</span><span style=color:#e6db74>}</span><span style=color:#e6db74>&#39;</span>)
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#75715e># 計算損失</span>
</span></span><span style=display:flex><span>    avg_loss <span style=color:#f92672>=</span> running_loss <span style=color:#f92672>/</span> len(trainset)
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Epoch </span><span style=color:#e6db74>{</span>epoch <span style=color:#f92672>+</span> <span style=color:#ae81ff>1</span><span style=color:#e6db74>}</span><span style=color:#e6db74> 訓練損失: </span><span style=color:#e6db74>{</span>avg_loss<span style=color:#e6db74>:</span><span style=color:#e6db74>.4f</span><span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span><span style=color:#75715e># 切換到評估模式</span>
</span></span><span style=display:flex><span>model<span style=color:#f92672>.</span>eval()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>correct <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span>total <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span><span style=color:#75715e># 不計算梯度</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>with</span> torch<span style=color:#f92672>.</span>no_grad():
</span></span><span style=display:flex><span>    <span style=color:#75715e># 將測試集載入，並顯示進度條</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> images, labels <span style=color:#f92672>in</span> tqdm(testloader, desc<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;Testing&#34;</span>, unit<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;batch&#34;</span>):
</span></span><span style=display:flex><span>        <span style=color:#75715e># 測試集設定設備</span>
</span></span><span style=display:flex><span>        images, labels <span style=color:#f92672>=</span> images<span style=color:#f92672>.</span>to(device), labels<span style=color:#f92672>.</span>to(device)
</span></span><span style=display:flex><span>        <span style=color:#75715e># 執行模型</span>
</span></span><span style=display:flex><span>        outputs <span style=color:#f92672>=</span> net(images)
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        <span style=color:#75715e># 輸出</span>
</span></span><span style=display:flex><span>        predicted <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>argmax(outputs, dim<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        <span style=color:#75715e># 計算樣本數</span>
</span></span><span style=display:flex><span>        total <span style=color:#f92672>+=</span> labels<span style=color:#f92672>.</span>size(<span style=color:#ae81ff>0</span>)
</span></span><span style=display:flex><span>        <span style=color:#75715e># 計算正確值</span>
</span></span><span style=display:flex><span>        correct <span style=color:#f92672>+=</span> (predicted <span style=color:#f92672>==</span> labels)<span style=color:#f92672>.</span>sum()<span style=color:#f92672>.</span>item()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>test_acc <span style=color:#f92672>=</span> correct <span style=color:#f92672>/</span> total
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>測試集準確率 (Test Accuracy): </span><span style=color:#e6db74>{</span>test_acc<span style=color:#e6db74>:</span><span style=color:#e6db74>.4f</span><span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 切換到訓練模式</span>
</span></span><span style=display:flex><span>model<span style=color:#f92672>.</span>train()
</span></span></code></pre></div><h3 id=yolo-v1>yolo v1</h3><p>cnn的進化版，這是v1版現在已經十幾版了，之後模型越來越複雜。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py><span style=display:flex><span><span style=color:#f92672>import</span> torch
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> torch <span style=color:#f92672>import</span> nn, optim
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> torch.utils.data <span style=color:#f92672>import</span> TensorDataset, DataLoader, random_split
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> torchvision <span style=color:#f92672>import</span> datasets, transforms
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> tqdm <span style=color:#f92672>import</span> tqdm
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 使用顯卡或cpu執行</span>
</span></span><span style=display:flex><span>device <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>device(<span style=color:#e6db74>&#39;cuda&#39;</span> <span style=color:#66d9ef>if</span> torch<span style=color:#f92672>.</span>cuda<span style=color:#f92672>.</span>is_available() <span style=color:#66d9ef>else</span> <span style=color:#e6db74>&#39;cpu&#39;</span>)
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;使用的設備: </span><span style=color:#e6db74>{</span>device<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 將資料轉換</span>
</span></span><span style=display:flex><span>transform <span style=color:#f92672>=</span> transforms<span style=color:#f92672>.</span>Compose([
</span></span><span style=display:flex><span>    <span style=color:#75715e># 更改圖片大小</span>
</span></span><span style=display:flex><span>    transforms<span style=color:#f92672>.</span>Resize(<span style=color:#ae81ff>224</span>),
</span></span><span style=display:flex><span>    <span style=color:#75715e># 將資料轉換Tensor 格式</span>
</span></span><span style=display:flex><span>    transforms<span style=color:#f92672>.</span>PILToTensor(),
</span></span><span style=display:flex><span>    <span style=color:#75715e># 轉換型態</span>
</span></span><span style=display:flex><span>    transforms<span style=color:#f92672>.</span>ConvertImageDtype(torch<span style=color:#f92672>.</span>float)
</span></span><span style=display:flex><span>])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 載入訓練集，載入位置，是否為訓練集，如果沒有就下載</span>
</span></span><span style=display:flex><span>trainset <span style=color:#f92672>=</span> datasets<span style=color:#f92672>.</span>CIFAR10(
</span></span><span style=display:flex><span>    root<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;./data&#39;</span>,
</span></span><span style=display:flex><span>    train<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>,
</span></span><span style=display:flex><span>    download<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>,
</span></span><span style=display:flex><span>    transform<span style=color:#f92672>=</span>transform
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span><span style=color:#75715e># 載入測試集，載入位置，是否為訓練集，如果沒有就下載</span>
</span></span><span style=display:flex><span>testset <span style=color:#f92672>=</span> datasets<span style=color:#f92672>.</span>CIFAR10(
</span></span><span style=display:flex><span>    root<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;./data&#39;</span>,
</span></span><span style=display:flex><span>    train<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>,
</span></span><span style=display:flex><span>    download<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>,
</span></span><span style=display:flex><span>    transform<span style=color:#f92672>=</span>transform
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 分割訓練集8:2分 (訓練集與驗證集)</span>
</span></span><span style=display:flex><span>train_size <span style=color:#f92672>=</span> int((<span style=color:#ae81ff>1</span> <span style=color:#f92672>-</span> <span style=color:#ae81ff>0.2</span>) <span style=color:#f92672>*</span> len(trainset))
</span></span><span style=display:flex><span>val_size <span style=color:#f92672>=</span> len(trainset) <span style=color:#f92672>-</span> train_size
</span></span><span style=display:flex><span>train_dataset, val_dataset <span style=color:#f92672>=</span> random_split(trainset, [train_size, val_size])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 資料集分群批</span>
</span></span><span style=display:flex><span>BATCH_SIZE <span style=color:#f92672>=</span> <span style=color:#ae81ff>64</span>
</span></span><span style=display:flex><span>trainloader <span style=color:#f92672>=</span> DataLoader(train_dataset, batch_size<span style=color:#f92672>=</span>BATCH_SIZE, shuffle<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span><span style=display:flex><span>valloader <span style=color:#f92672>=</span> DataLoader(val_dataset, batch_size<span style=color:#f92672>=</span>BATCH_SIZE, shuffle<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>)
</span></span><span style=display:flex><span>testloader <span style=color:#f92672>=</span> DataLoader(testset, batch_size<span style=color:#f92672>=</span>BATCH_SIZE, shuffle<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 模型</span>
</span></span><span style=display:flex><span>model <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Sequential(
</span></span><span style=display:flex><span>    <span style=color:#75715e># 卷積層 找出圖片特徵，在圖片中找出64個7x7大小範圍內的特徵，並將小於0值為0，輸入為3層</span>
</span></span><span style=display:flex><span>    nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>64</span>, (<span style=color:#ae81ff>7</span>, <span style=color:#ae81ff>7</span>)), nn<span style=color:#f92672>.</span>ReLU(),
</span></span><span style=display:flex><span>    <span style=color:#75715e># 池化層 減少值數量找到最大值，以2x2大小找</span>
</span></span><span style=display:flex><span>    nn<span style=color:#f92672>.</span>MaxPool2d((<span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>2</span>), stride<span style=color:#f92672>=</span>(<span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>2</span>)),
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 卷積層 找出圖片特徵，在圖片中找出192個3x3大小範圍內的特徵，並將小於0值為0,並在周圍補0，輸入為64層</span>
</span></span><span style=display:flex><span>    nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>64</span>, <span style=color:#ae81ff>192</span>, (<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>3</span>), padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>), nn<span style=color:#f92672>.</span>ReLU(),
</span></span><span style=display:flex><span>    <span style=color:#75715e># 池化層 減少值數量找到最大值，以2x2大小找</span>
</span></span><span style=display:flex><span>    nn<span style=color:#f92672>.</span>MaxPool2d((<span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>2</span>), stride<span style=color:#f92672>=</span>(<span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>2</span>)),
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 卷積層 找出圖片特徵，在圖片中找出128個1x1大小範圍內的特徵，並將小於0值為0,並在周圍補0，輸入為192層</span>
</span></span><span style=display:flex><span>    nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>192</span>, <span style=color:#ae81ff>128</span>, (<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>), padding<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>), nn<span style=color:#f92672>.</span>ReLU(),
</span></span><span style=display:flex><span>    <span style=color:#75715e># 卷積層 找出圖片特徵，在圖片中找出256個3x3大小範圍內的特徵，並將小於0值為0,並在周圍補0，輸入為128層</span>
</span></span><span style=display:flex><span>    nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>128</span>, <span style=color:#ae81ff>256</span>, (<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>3</span>), padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>), nn<span style=color:#f92672>.</span>ReLU(),
</span></span><span style=display:flex><span>    <span style=color:#75715e># 卷積層 找出圖片特徵，在圖片中找出256個1x1大小範圍內的特徵，並將小於0值為0,並在周圍補0，輸入為256層</span>
</span></span><span style=display:flex><span>    nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>256</span>, <span style=color:#ae81ff>256</span>, (<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>), padding<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>), nn<span style=color:#f92672>.</span>ReLU(),
</span></span><span style=display:flex><span>    <span style=color:#75715e># 卷積層 找出圖片特徵，在圖片中找出512個3x3大小範圍內的特徵，並將小於0值為0,並在周圍補0，輸入為256層</span>
</span></span><span style=display:flex><span>    nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>256</span>, <span style=color:#ae81ff>512</span>, (<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>3</span>), padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>), nn<span style=color:#f92672>.</span>ReLU(),
</span></span><span style=display:flex><span>    <span style=color:#75715e># 池化層 減少值數量找到最大值，以2x2大小找</span>
</span></span><span style=display:flex><span>    nn<span style=color:#f92672>.</span>MaxPool2d((<span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>2</span>), stride<span style=color:#f92672>=</span>(<span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>2</span>)),
</span></span><span style=display:flex><span>    <span style=color:#75715e># 卷積層 找出圖片特徵，在圖片中找出256個1x1大小範圍內的特徵，並將小於0值為0,並在周圍補0，輸入為512層</span>
</span></span><span style=display:flex><span>    nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>512</span>, <span style=color:#ae81ff>256</span>, (<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>), padding<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>), nn<span style=color:#f92672>.</span>ReLU(),
</span></span><span style=display:flex><span>    <span style=color:#75715e># 卷積層 找出圖片特徵，在圖片中找出512個3x3大小範圍內的特徵，並將小於0值為0,並在周圍補0，輸入為256層</span>
</span></span><span style=display:flex><span>    nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>256</span>, <span style=color:#ae81ff>512</span>, (<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>3</span>), padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>), nn<span style=color:#f92672>.</span>ReLU(),
</span></span><span style=display:flex><span>    <span style=color:#75715e># 卷積層 找出圖片特徵，在圖片中找出256個1x1大小範圍內的特徵，並將小於0值為0,並在周圍補0，輸入為512層</span>
</span></span><span style=display:flex><span>    nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>512</span>, <span style=color:#ae81ff>256</span>, (<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>), padding<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>), nn<span style=color:#f92672>.</span>ReLU(),
</span></span><span style=display:flex><span>    <span style=color:#75715e># 卷積層 找出圖片特徵，在圖片中找出512個3x3大小範圍內的特徵，並將小於0值為0,並在周圍補0，輸入為256層</span>
</span></span><span style=display:flex><span>    nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>256</span>, <span style=color:#ae81ff>512</span>, (<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>3</span>), padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>), nn<span style=color:#f92672>.</span>ReLU(),
</span></span><span style=display:flex><span>    <span style=color:#75715e># 卷積層 找出圖片特徵，在圖片中找出256個1x1大小範圍內的特徵，並將小於0值為0,並在周圍補0，輸入為512層</span>
</span></span><span style=display:flex><span>    nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>512</span>, <span style=color:#ae81ff>256</span>, (<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>), padding<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>), nn<span style=color:#f92672>.</span>ReLU(),
</span></span><span style=display:flex><span>    <span style=color:#75715e># 卷積層 找出圖片特徵，在圖片中找出512個3x3大小範圍內的特徵，並將小於0值為0,並在周圍補0，輸入為256層</span>
</span></span><span style=display:flex><span>    nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>256</span>, <span style=color:#ae81ff>512</span>, (<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>3</span>), padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>), nn<span style=color:#f92672>.</span>ReLU(),
</span></span><span style=display:flex><span>    <span style=color:#75715e># 卷積層 找出圖片特徵，在圖片中找出256個1x1大小範圍內的特徵，並將小於0值為0,並在周圍補0，輸入為512層</span>
</span></span><span style=display:flex><span>    nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>512</span>, <span style=color:#ae81ff>256</span>, (<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>), padding<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>), nn<span style=color:#f92672>.</span>ReLU(),
</span></span><span style=display:flex><span>    <span style=color:#75715e># 卷積層 找出圖片特徵，在圖片中找出512個3x3大小範圍內的特徵，並將小於0值為0,並在周圍補0，輸入為256層</span>
</span></span><span style=display:flex><span>    nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>256</span>, <span style=color:#ae81ff>512</span>, (<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>3</span>), padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>), nn<span style=color:#f92672>.</span>ReLU(),
</span></span><span style=display:flex><span>    <span style=color:#75715e># 卷積層 找出圖片特徵，在圖片中找出512個1x1大小範圍內的特徵，並將小於0值為0,並在周圍補0，輸入為512層</span>
</span></span><span style=display:flex><span>    nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>512</span>, <span style=color:#ae81ff>512</span>, (<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>), padding<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>), nn<span style=color:#f92672>.</span>ReLU(),
</span></span><span style=display:flex><span>    <span style=color:#75715e># 卷積層 找出圖片特徵，在圖片中找出1024個3x3大小範圍內的特徵，並將小於0值為0,並在周圍補0，輸入為512層</span>
</span></span><span style=display:flex><span>    nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>512</span>, <span style=color:#ae81ff>1024</span>, (<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>3</span>), padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>), nn<span style=color:#f92672>.</span>ReLU(),
</span></span><span style=display:flex><span>    <span style=color:#75715e># 池化層 減少值數量找到最大值，以2x2大小找</span>
</span></span><span style=display:flex><span>    nn<span style=color:#f92672>.</span>MaxPool2d((<span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>2</span>), stride<span style=color:#f92672>=</span>(<span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>2</span>)),
</span></span><span style=display:flex><span>    <span style=color:#75715e># 卷積層 找出圖片特徵，在圖片中找出512個1x1大小範圍內的特徵，並將小於0值為0,並在周圍補0，輸入為1024層</span>
</span></span><span style=display:flex><span>    nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>1024</span>, <span style=color:#ae81ff>512</span>, (<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>), padding<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>), nn<span style=color:#f92672>.</span>ReLU(),
</span></span><span style=display:flex><span>    <span style=color:#75715e># 卷積層 找出圖片特徵，在圖片中找出1024個3x3大小範圍內的特徵，並將小於0值為0,並在周圍補0，輸入為512層</span>
</span></span><span style=display:flex><span>    nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>512</span>, <span style=color:#ae81ff>1024</span>, (<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>3</span>), padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>), nn<span style=color:#f92672>.</span>ReLU(),
</span></span><span style=display:flex><span>    <span style=color:#75715e># 卷積層 找出圖片特徵，在圖片中找出512個1x1大小範圍內的特徵，並將小於0值為0,並在周圍補0，輸入為1024層</span>
</span></span><span style=display:flex><span>    nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>1024</span>, <span style=color:#ae81ff>512</span>, (<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>), padding<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>), nn<span style=color:#f92672>.</span>ReLU(),
</span></span><span style=display:flex><span>    <span style=color:#75715e># 卷積層 找出圖片特徵，在圖片中找出1024個3x3大小範圍內的特徵，並將小於0值為0,並在周圍補0，輸入為512層</span>
</span></span><span style=display:flex><span>    nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>512</span>, <span style=color:#ae81ff>1024</span>, (<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>3</span>), padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>), nn<span style=color:#f92672>.</span>ReLU(),
</span></span><span style=display:flex><span>    <span style=color:#75715e># 卷積層 找出圖片特徵，在圖片中找出1024個3x3大小範圍內的特徵，並將小於0值為0,並在周圍補0，輸入為1024層</span>
</span></span><span style=display:flex><span>    nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>1024</span>, <span style=color:#ae81ff>1024</span>, (<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>3</span>), padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>), nn<span style=color:#f92672>.</span>ReLU(),
</span></span><span style=display:flex><span>    <span style=color:#75715e># 卷積層 找出圖片特徵，在圖片中找出1024個3x3大小範圍內的特徵，，以間4x4位移,並將小於0值為0,並在周圍補0，輸入為1024層</span>
</span></span><span style=display:flex><span>    nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>1024</span>, <span style=color:#ae81ff>1024</span>, (<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>3</span>), padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>, stride<span style=color:#f92672>=</span>(<span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>2</span>)), nn<span style=color:#f92672>.</span>ReLU(),
</span></span><span style=display:flex><span>    <span style=color:#75715e># 卷積層 找出圖片特徵，在圖片中找出1024個3x3大小範圍內的特徵，並將小於0值為0,並在周圍補0，輸入為1024層</span>
</span></span><span style=display:flex><span>    nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>1024</span>, <span style=color:#ae81ff>1024</span>, (<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>3</span>), padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>), nn<span style=color:#f92672>.</span>ReLU(),
</span></span><span style=display:flex><span>    <span style=color:#75715e># 卷積層 找出圖片特徵，在圖片中找出1024個3x3大小範圍內的特徵，並將小於0值為0,並在周圍補0，輸入為1024層</span>
</span></span><span style=display:flex><span>    nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>1024</span>, <span style=color:#ae81ff>1024</span>, (<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>3</span>), padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>), nn<span style=color:#f92672>.</span>ReLU(),
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 攤平層 將二維轉換一維</span>
</span></span><span style=display:flex><span>    nn<span style=color:#f92672>.</span>Flatten(),
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 全連接層 將攤平層整理出4096的輸出</span>
</span></span><span style=display:flex><span>    nn<span style=color:#f92672>.</span>Linear(<span style=color:#ae81ff>1024</span> <span style=color:#f92672>*</span> <span style=color:#ae81ff>7</span> <span style=color:#f92672>*</span> <span style=color:#ae81ff>7</span>, <span style=color:#ae81ff>4096</span>), nn<span style=color:#f92672>.</span>ReLU(),
</span></span><span style=display:flex><span>    <span style=color:#75715e># 全連接層 最後整理輸出訓練集所分類的(網格數量(7*7)*(邊框數量(2)*邊框資訊(5)*類別數量(10)))個</span>
</span></span><span style=display:flex><span>    nn<span style=color:#f92672>.</span>Linear(<span style=color:#ae81ff>4096</span>, <span style=color:#ae81ff>7</span> <span style=color:#f92672>*</span> <span style=color:#ae81ff>7</span> <span style=color:#f92672>*</span> (<span style=color:#ae81ff>2</span> <span style=color:#f92672>*</span> <span style=color:#ae81ff>5</span> <span style=color:#f92672>+</span> <span style=color:#ae81ff>10</span>))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>)<span style=color:#f92672>.</span>to(device)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 設定損失</span>
</span></span><span style=display:flex><span>criterion <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>CrossEntropyLoss()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 設定優化</span>
</span></span><span style=display:flex><span>optimizer <span style=color:#f92672>=</span> optim<span style=color:#f92672>.</span>Adam(model<span style=color:#f92672>.</span>parameters(), lr<span style=color:#f92672>=</span><span style=color:#ae81ff>0.001</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>NUM_EPOCHS <span style=color:#f92672>=</span> <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 設定訓練次數</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> epoch <span style=color:#f92672>in</span> range(NUM_EPOCHS):
</span></span><span style=display:flex><span>    <span style=color:#75715e># 初始化損失和準確和數量</span>
</span></span><span style=display:flex><span>    total_loss, total_correct, total_count <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 設定進度條，將訓練集載入</span>
</span></span><span style=display:flex><span>    train_loop <span style=color:#f92672>=</span> tqdm(
</span></span><span style=display:flex><span>        trainloader,
</span></span><span style=display:flex><span>        desc<span style=color:#f92672>=</span><span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Epoch </span><span style=color:#e6db74>{</span>epoch <span style=color:#f92672>+</span> <span style=color:#ae81ff>1</span><span style=color:#e6db74>}</span><span style=color:#e6db74>/</span><span style=color:#e6db74>{</span><span style=color:#ae81ff>1</span><span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>,
</span></span><span style=display:flex><span>        unit<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;batch&#34;</span>,
</span></span><span style=display:flex><span>        leave<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>
</span></span><span style=display:flex><span>    )
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 使用進度調</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> inputs, labels <span style=color:#f92672>in</span> train_loop:
</span></span><span style=display:flex><span>        <span style=color:#75715e># 訓練集設定設備</span>
</span></span><span style=display:flex><span>        inputs, labels <span style=color:#f92672>=</span> inputs<span style=color:#f92672>.</span>to(device), labels<span style=color:#f92672>.</span>to(device)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># 梯度歸零，因為pytocrh的梯度不會規零，主要原因是批次訓練</span>
</span></span><span style=display:flex><span>        optimizer<span style=color:#f92672>.</span>zero_grad()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># 執行模型</span>
</span></span><span style=display:flex><span>        outputs <span style=color:#f92672>=</span> model(inputs)
</span></span><span style=display:flex><span>        <span style=color:#75715e># 取得損失</span>
</span></span><span style=display:flex><span>        loss <span style=color:#f92672>=</span> criterion(outputs, labels)
</span></span><span style=display:flex><span>        <span style=color:#75715e># 反向傳播</span>
</span></span><span style=display:flex><span>        loss<span style=color:#f92672>.</span>backward()
</span></span><span style=display:flex><span>        <span style=color:#75715e># 更新權重</span>
</span></span><span style=display:flex><span>        optimizer<span style=color:#f92672>.</span>step()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># 顯示損失</span>
</span></span><span style=display:flex><span>        train_loop<span style=color:#f92672>.</span>set_postfix(loss<span style=color:#f92672>=</span><span style=color:#e6db74>f</span><span style=color:#e6db74>&#39;</span><span style=color:#e6db74>{</span>loss<span style=color:#f92672>.</span>item()<span style=color:#e6db74>:</span><span style=color:#e6db74>.4f</span><span style=color:#e6db74>}</span><span style=color:#e6db74>&#39;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># 轉換預測值 (argmax 獲取最高 Log-機率的索引)</span>
</span></span><span style=display:flex><span>        predicted <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>argmax(outputs, dim<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>        <span style=color:#75715e># 將預測直查詢相加次數</span>
</span></span><span style=display:flex><span>        total_correct <span style=color:#f92672>+=</span> (predicted <span style=color:#f92672>==</span> labels)<span style=color:#f92672>.</span>sum()<span style=color:#f92672>.</span>item()
</span></span><span style=display:flex><span>        <span style=color:#75715e># 加總損失</span>
</span></span><span style=display:flex><span>        total_loss <span style=color:#f92672>+=</span> loss<span style=color:#f92672>.</span>item() <span style=color:#f92672>*</span> inputs<span style=color:#f92672>.</span>size(<span style=color:#ae81ff>0</span>)
</span></span><span style=display:flex><span>        <span style=color:#75715e># 加總訓練資料數量</span>
</span></span><span style=display:flex><span>        total_count <span style=color:#f92672>+=</span> inputs<span style=color:#f92672>.</span>size(<span style=color:#ae81ff>0</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 訓練結果輸出</span>
</span></span><span style=display:flex><span>    train_loss_avg <span style=color:#f92672>=</span> total_loss <span style=color:#f92672>/</span> total_count
</span></span><span style=display:flex><span>    train_acc_avg <span style=color:#f92672>=</span> total_correct <span style=color:#f92672>/</span> total_count
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#39;Epoch </span><span style=color:#e6db74>{</span>epoch<span style=color:#f92672>+</span><span style=color:#ae81ff>1</span><span style=color:#e6db74>}</span><span style=color:#e6db74>/</span><span style=color:#e6db74>{</span>NUM_EPOCHS<span style=color:#e6db74>}</span><span style=color:#e6db74> - loss: </span><span style=color:#e6db74>{</span>train_loss_avg<span style=color:#e6db74>:</span><span style=color:#e6db74>.4f</span><span style=color:#e6db74>}</span><span style=color:#e6db74> - acc: </span><span style=color:#e6db74>{</span>train_acc_avg<span style=color:#e6db74>:</span><span style=color:#e6db74>.4f</span><span style=color:#e6db74>}</span><span style=color:#e6db74>&#39;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 切換到評估模式</span>
</span></span><span style=display:flex><span>model<span style=color:#f92672>.</span>eval()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>correct <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span>total <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span><span style=color:#75715e># 不計算梯度</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>with</span> torch<span style=color:#f92672>.</span>no_grad():
</span></span><span style=display:flex><span>    <span style=color:#75715e># 初始化損失和準確和數量</span>
</span></span><span style=display:flex><span>    total_loss, total_correct, total_count <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> inputs, labels <span style=color:#f92672>in</span> tqdm(valloader, desc<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;驗證 (Validation)&#34;</span>, unit<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;batch&#34;</span>):
</span></span><span style=display:flex><span>        <span style=color:#75715e># 驗證集設定設備</span>
</span></span><span style=display:flex><span>        inputs, labels <span style=color:#f92672>=</span> inputs<span style=color:#f92672>.</span>to(device), labels<span style=color:#f92672>.</span>to(device)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># 執行模型</span>
</span></span><span style=display:flex><span>        outputs <span style=color:#f92672>=</span> model(inputs)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># 取得損失</span>
</span></span><span style=display:flex><span>        loss <span style=color:#f92672>=</span> criterion(outputs, labels)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># 轉換預測值</span>
</span></span><span style=display:flex><span>        predicted <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>argmax(outputs, dim<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>        <span style=color:#75715e># 將預測直查詢相加次數</span>
</span></span><span style=display:flex><span>        total_correct <span style=color:#f92672>+=</span> (predicted <span style=color:#f92672>==</span> labels)<span style=color:#f92672>.</span>sum()<span style=color:#f92672>.</span>item()
</span></span><span style=display:flex><span>        <span style=color:#75715e># 加總損失</span>
</span></span><span style=display:flex><span>        total_loss <span style=color:#f92672>+=</span> loss<span style=color:#f92672>.</span>item() <span style=color:#f92672>*</span> inputs<span style=color:#f92672>.</span>size(<span style=color:#ae81ff>0</span>)
</span></span><span style=display:flex><span>        <span style=color:#75715e># 加總訓練資料數量</span>
</span></span><span style=display:flex><span>        total_count <span style=color:#f92672>+=</span> inputs<span style=color:#f92672>.</span>size(<span style=color:#ae81ff>0</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>&#39;=&#39;</span><span style=color:#f92672>*</span><span style=color:#ae81ff>50</span>)
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#39;驗證結果 - loss: </span><span style=color:#e6db74>{</span>total_loss <span style=color:#f92672>/</span> total_count<span style=color:#e6db74>:</span><span style=color:#e6db74>.4f</span><span style=color:#e6db74>}</span><span style=color:#e6db74> - acc: </span><span style=color:#e6db74>{</span>total_correct <span style=color:#f92672>/</span> total_count<span style=color:#e6db74>:</span><span style=color:#e6db74>.4f</span><span style=color:#e6db74>}</span><span style=color:#e6db74>&#39;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>&#39;=&#39;</span><span style=color:#f92672>*</span><span style=color:#ae81ff>50</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 初始化損失和準確和數量</span>
</span></span><span style=display:flex><span>    total_loss, total_correct, total_count <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> inputs, labels <span style=color:#f92672>in</span> tqdm(testloader, desc<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;最終測試 (Testing)&#34;</span>, unit<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;batch&#34;</span>):
</span></span><span style=display:flex><span>        <span style=color:#75715e># 測試集設定設備</span>
</span></span><span style=display:flex><span>        inputs, labels <span style=color:#f92672>=</span> inputs<span style=color:#f92672>.</span>to(device), labels<span style=color:#f92672>.</span>to(device)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># 執行模型</span>
</span></span><span style=display:flex><span>        outputs <span style=color:#f92672>=</span> model(inputs)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># 取得損失</span>
</span></span><span style=display:flex><span>        loss <span style=color:#f92672>=</span> criterion(outputs, labels)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># 轉換預測值</span>
</span></span><span style=display:flex><span>        predicted <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>argmax(outputs, dim<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>        <span style=color:#75715e># 將預測直查詢相加次數</span>
</span></span><span style=display:flex><span>        total_correct <span style=color:#f92672>+=</span> (predicted <span style=color:#f92672>==</span> labels)<span style=color:#f92672>.</span>sum()<span style=color:#f92672>.</span>item()
</span></span><span style=display:flex><span>        <span style=color:#75715e># 加總損失</span>
</span></span><span style=display:flex><span>        total_loss <span style=color:#f92672>+=</span> loss<span style=color:#f92672>.</span>item() <span style=color:#f92672>*</span> inputs<span style=color:#f92672>.</span>size(<span style=color:#ae81ff>0</span>)
</span></span><span style=display:flex><span>        <span style=color:#75715e># 加總訓練資料數量</span>
</span></span><span style=display:flex><span>        total_count <span style=color:#f92672>+=</span> inputs<span style=color:#f92672>.</span>size(<span style=color:#ae81ff>0</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>&#39;=&#39;</span><span style=color:#f92672>*</span><span style=color:#ae81ff>50</span>)
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#39;測試集結果 - loss: </span><span style=color:#e6db74>{</span>total_loss <span style=color:#f92672>/</span> total_count<span style=color:#e6db74>:</span><span style=color:#e6db74>.4f</span><span style=color:#e6db74>}</span><span style=color:#e6db74> - acc: </span><span style=color:#e6db74>{</span>total_correct <span style=color:#f92672>/</span> total_count<span style=color:#e6db74>:</span><span style=color:#e6db74>.4f</span><span style=color:#e6db74>}</span><span style=color:#e6db74>&#39;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 切換到訓練模式</span>
</span></span><span style=display:flex><span>model<span style=color:#f92672>.</span>train()
</span></span></code></pre></div><h3 id=resnet>ResNet</h3><p>較為特別cnn，特別的點是會將訓練過後和訓練前的結果相加。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py><span style=display:flex><span><span style=color:#f92672>import</span> torch
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> torch <span style=color:#f92672>import</span> nn, optim
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> torch.utils.data <span style=color:#f92672>import</span> TensorDataset, DataLoader, random_split
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> torchvision <span style=color:#f92672>import</span> datasets, transforms
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> tqdm <span style=color:#f92672>import</span> tqdm
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 使用顯卡或cpu執行</span>
</span></span><span style=display:flex><span>device <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>device(<span style=color:#e6db74>&#39;cuda&#39;</span> <span style=color:#66d9ef>if</span> torch<span style=color:#f92672>.</span>cuda<span style=color:#f92672>.</span>is_available() <span style=color:#66d9ef>else</span> <span style=color:#e6db74>&#39;cpu&#39;</span>)
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;使用的設備: </span><span style=color:#e6db74>{</span>device<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 將資料轉換</span>
</span></span><span style=display:flex><span>transform <span style=color:#f92672>=</span> transforms<span style=color:#f92672>.</span>Compose([
</span></span><span style=display:flex><span>    <span style=color:#75715e># 更改圖片大小</span>
</span></span><span style=display:flex><span>    transforms<span style=color:#f92672>.</span>Resize(<span style=color:#ae81ff>224</span>),
</span></span><span style=display:flex><span>    <span style=color:#75715e># 將資料轉換Tensor 格式</span>
</span></span><span style=display:flex><span>    transforms<span style=color:#f92672>.</span>PILToTensor(),
</span></span><span style=display:flex><span>    <span style=color:#75715e># 轉換型態</span>
</span></span><span style=display:flex><span>    transforms<span style=color:#f92672>.</span>ConvertImageDtype(torch<span style=color:#f92672>.</span>float)
</span></span><span style=display:flex><span>])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 載入訓練集，載入位置，是否為訓練集，如果沒有就下載</span>
</span></span><span style=display:flex><span>trainset <span style=color:#f92672>=</span> datasets<span style=color:#f92672>.</span>CIFAR10(
</span></span><span style=display:flex><span>    root<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;./data&#39;</span>,
</span></span><span style=display:flex><span>    train<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>,
</span></span><span style=display:flex><span>    download<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>,
</span></span><span style=display:flex><span>    transform<span style=color:#f92672>=</span>transform
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span><span style=color:#75715e># 載入測試集，載入位置，是否為訓練集，如果沒有就下載</span>
</span></span><span style=display:flex><span>testset <span style=color:#f92672>=</span> datasets<span style=color:#f92672>.</span>CIFAR10(
</span></span><span style=display:flex><span>    root<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;./data&#39;</span>,
</span></span><span style=display:flex><span>    train<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>,
</span></span><span style=display:flex><span>    download<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>,
</span></span><span style=display:flex><span>    transform<span style=color:#f92672>=</span>transform
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 分割訓練集8:2分 (訓練集與驗證集)</span>
</span></span><span style=display:flex><span>train_size <span style=color:#f92672>=</span> int((<span style=color:#ae81ff>1</span> <span style=color:#f92672>-</span> <span style=color:#ae81ff>0.2</span>) <span style=color:#f92672>*</span> len(trainset))
</span></span><span style=display:flex><span>val_size <span style=color:#f92672>=</span> len(trainset) <span style=color:#f92672>-</span> train_size
</span></span><span style=display:flex><span>train_dataset, val_dataset <span style=color:#f92672>=</span> random_split(trainset, [train_size, val_size])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 資料集分群批</span>
</span></span><span style=display:flex><span>BATCH_SIZE <span style=color:#f92672>=</span> <span style=color:#ae81ff>64</span>
</span></span><span style=display:flex><span>trainloader <span style=color:#f92672>=</span> DataLoader(train_dataset, batch_size<span style=color:#f92672>=</span>BATCH_SIZE, shuffle<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span><span style=display:flex><span>valloader <span style=color:#f92672>=</span> DataLoader(val_dataset, batch_size<span style=color:#f92672>=</span>BATCH_SIZE, shuffle<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>)
</span></span><span style=display:flex><span>testloader <span style=color:#f92672>=</span> DataLoader(testset, batch_size<span style=color:#f92672>=</span>BATCH_SIZE, shuffle<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 模型</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>ResNet</span>(nn<span style=color:#f92672>.</span>Module):
</span></span><span style=display:flex><span>    <span style=color:#75715e># 這裡的初始化用於定義所有的層</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> __init__(self, num_classes<span style=color:#f92672>=</span><span style=color:#ae81ff>10</span>):
</span></span><span style=display:flex><span>        super(ResNet, self)<span style=color:#f92672>.</span>__init__()
</span></span><span style=display:flex><span>        <span style=color:#75715e># 並將小於0值為0</span>
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>layersrelu <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>ReLU(inplace<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span><span style=display:flex><span>        <span style=color:#75715e># 初始卷積層</span>
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>features_shared <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Sequential(
</span></span><span style=display:flex><span>            <span style=color:#75715e># 找出圖片特徵，在圖片中找出64個7x7大小範圍內的特徵，以間2x2位移，輸入為3層</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>64</span>, (<span style=color:#ae81ff>7</span>, <span style=color:#ae81ff>7</span>), stride<span style=color:#f92672>=</span>(<span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>2</span>), padding<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span>), 
</span></span><span style=display:flex><span>            <span style=color:#75715e># 輔助層 將資料逕行整理以便後續分析</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>BatchNorm2d(<span style=color:#ae81ff>64</span>),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 並將小於0值為0</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>ReLU(),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 池化層 減少值數量找到最大值，以3x3大小找並以2x2位移</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>MaxPool2d(kernel_size<span style=color:#f92672>=</span>(<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>3</span>), stride<span style=color:#f92672>=</span>(<span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>2</span>), padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>        )
</span></span><span style=display:flex><span>        <span style=color:#75715e># 64個</span>
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>layers64_1 <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Sequential(
</span></span><span style=display:flex><span>            <span style=color:#75715e># 找出圖片特徵，在圖片中找出64個3x3大小範圍內的特徵，以間1x1位移，輸入為64層</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>64</span>, <span style=color:#ae81ff>64</span>, (<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>3</span>), stride<span style=color:#f92672>=</span>(<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>), padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>), 
</span></span><span style=display:flex><span>            <span style=color:#75715e># 輔助層 將資料逕行整理以便後續分析</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>BatchNorm2d(<span style=color:#ae81ff>64</span>),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 並將小於0值為0</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>ReLU(),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 找出圖片特徵，在圖片中找出64個3x3大小範圍內的特徵，以間1x1位移，輸入為64層</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>64</span>, <span style=color:#ae81ff>64</span>, (<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>3</span>), stride<span style=color:#f92672>=</span>(<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>), padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>), 
</span></span><span style=display:flex><span>            <span style=color:#75715e># 輔助層 將資料逕行整理以便後續分析</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>BatchNorm2d(<span style=color:#ae81ff>64</span>)
</span></span><span style=display:flex><span>        )
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>layers64_2 <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Sequential(
</span></span><span style=display:flex><span>            <span style=color:#75715e># 找出圖片特徵，在圖片中找出64個3x3大小範圍內的特徵，以間1x1位移，輸入為64層</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>64</span>, <span style=color:#ae81ff>64</span>, (<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>3</span>), stride<span style=color:#f92672>=</span>(<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>), padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>), 
</span></span><span style=display:flex><span>            <span style=color:#75715e># 輔助層 將資料逕行整理以便後續分析</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>BatchNorm2d(<span style=color:#ae81ff>64</span>),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 並將小於0值為0</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>ReLU(),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 找出圖片特徵，在圖片中找出64個3x3大小範圍內的特徵，以間1x1位移，輸入為64層</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>64</span>, <span style=color:#ae81ff>64</span>, (<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>3</span>), stride<span style=color:#f92672>=</span>(<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>), padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>), 
</span></span><span style=display:flex><span>            <span style=color:#75715e># 輔助層 將資料逕行整理以便後續分析</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>BatchNorm2d(<span style=color:#ae81ff>64</span>)
</span></span><span style=display:flex><span>        )
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>layers64_3 <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Sequential(
</span></span><span style=display:flex><span>            <span style=color:#75715e># 找出圖片特徵，在圖片中找出64個3x3大小範圍內的特徵，以間1x1位移，輸入為64層</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>64</span>, <span style=color:#ae81ff>64</span>, (<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>3</span>), stride<span style=color:#f92672>=</span>(<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>), padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>), 
</span></span><span style=display:flex><span>            <span style=color:#75715e># 輔助層 將資料逕行整理以便後續分析</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>BatchNorm2d(<span style=color:#ae81ff>64</span>),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 並將小於0值為0</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>ReLU(),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 找出圖片特徵，在圖片中找出64個3x3大小範圍內的特徵，以間1x1位移，輸入為64層</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>64</span>, <span style=color:#ae81ff>64</span>, (<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>3</span>), stride<span style=color:#f92672>=</span>(<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>), padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>), 
</span></span><span style=display:flex><span>            <span style=color:#75715e># 輔助層 將資料逕行整理以便後續分析</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>BatchNorm2d(<span style=color:#ae81ff>64</span>)
</span></span><span style=display:flex><span>        )
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>layers128_1 <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Sequential(
</span></span><span style=display:flex><span>            <span style=color:#75715e># 找出圖片特徵，在圖片中找出128個3x3大小範圍內的特徵，以間2x2位移，輸入為64層</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>64</span>, <span style=color:#ae81ff>128</span>, (<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>3</span>), stride<span style=color:#f92672>=</span>(<span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>2</span>), padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>), 
</span></span><span style=display:flex><span>            <span style=color:#75715e># 輔助層 將資料逕行整理以便後續分析</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>BatchNorm2d(<span style=color:#ae81ff>128</span>), <span style=color:#75715e># 修正參數</span>
</span></span><span style=display:flex><span>            <span style=color:#75715e># 並將小於0值為0</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>ReLU(),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 找出圖片特徵，在圖片中找出128個3x3大小範圍內的特徵，以間1x1位移，輸入為128層</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>128</span>, <span style=color:#ae81ff>128</span>, (<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>3</span>), stride<span style=color:#f92672>=</span>(<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>), padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>), 
</span></span><span style=display:flex><span>            <span style=color:#75715e># 輔助層 將資料逕行整理以便後續分析</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>BatchNorm2d(<span style=color:#ae81ff>128</span>) <span style=color:#75715e># 修正參數</span>
</span></span><span style=display:flex><span>        )
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>layers128_2 <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Sequential(
</span></span><span style=display:flex><span>            <span style=color:#75715e># 找出圖片特徵，在圖片中找出128個3x3大小範圍內的特徵，以間1x1位移，輸入為128層</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>128</span>, <span style=color:#ae81ff>128</span>, (<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>3</span>), stride<span style=color:#f92672>=</span>(<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>), padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>), 
</span></span><span style=display:flex><span>            <span style=color:#75715e># 輔助層 將資料逕行整理以便後續分析</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>BatchNorm2d(<span style=color:#ae81ff>128</span>), <span style=color:#75715e># 修正參數</span>
</span></span><span style=display:flex><span>            <span style=color:#75715e># 並將小於0值為0</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>ReLU(),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 找出圖片特徵，在圖片中找出128個3x3大小範圍內的特徵，以間1x1位移，輸入為128層</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>128</span>, <span style=color:#ae81ff>128</span>, (<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>3</span>), stride<span style=color:#f92672>=</span>(<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>), padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>), 
</span></span><span style=display:flex><span>            <span style=color:#75715e># 輔助層 將資料逕行整理以便後續分析</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>BatchNorm2d(<span style=color:#ae81ff>128</span>) <span style=color:#75715e># 修正參數</span>
</span></span><span style=display:flex><span>        )
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>layers128_3 <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Sequential(
</span></span><span style=display:flex><span>            <span style=color:#75715e># 找出圖片特徵，在圖片中找出128個3x3大小範圍內的特徵，以間1x1位移，輸入為128層</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>128</span>, <span style=color:#ae81ff>128</span>, (<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>3</span>), stride<span style=color:#f92672>=</span>(<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>), padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>), 
</span></span><span style=display:flex><span>            <span style=color:#75715e># 輔助層 將資料逕行整理以便後續分析</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>BatchNorm2d(<span style=color:#ae81ff>128</span>), <span style=color:#75715e># 修正參數</span>
</span></span><span style=display:flex><span>            <span style=color:#75715e># 並將小於0值為0</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>ReLU(),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 找出圖片特徵，在圖片中找出128個3x3大小範圍內的特徵，以間1x1位移，輸入為128層</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>128</span>, <span style=color:#ae81ff>128</span>, (<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>3</span>), stride<span style=color:#f92672>=</span>(<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>), padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>), 
</span></span><span style=display:flex><span>            <span style=color:#75715e># 輔助層 將資料逕行整理以便後續分析</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>BatchNorm2d(<span style=color:#ae81ff>128</span>) <span style=color:#75715e># 修正參數</span>
</span></span><span style=display:flex><span>        )
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>layers128_4 <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Sequential(
</span></span><span style=display:flex><span>            <span style=color:#75715e># 找出圖片特徵，在圖片中找出128個3x3大小範圍內的特徵，以間1x1位移，輸入為128層</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>128</span>, <span style=color:#ae81ff>128</span>, (<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>3</span>), stride<span style=color:#f92672>=</span>(<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>), padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>), 
</span></span><span style=display:flex><span>            <span style=color:#75715e># 輔助層 將資料逕行整理以便後續分析</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>BatchNorm2d(<span style=color:#ae81ff>128</span>), <span style=color:#75715e># 修正參數</span>
</span></span><span style=display:flex><span>            <span style=color:#75715e># 並將小於0值為0</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>ReLU(),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 找出圖片特徵，在圖片中找出128個3x3大小範圍內的特徵，以間1x1位移，輸入為128層</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>128</span>, <span style=color:#ae81ff>128</span>, (<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>3</span>), stride<span style=color:#f92672>=</span>(<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>), padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>), 
</span></span><span style=display:flex><span>            <span style=color:#75715e># 輔助層 將資料逕行整理以便後續分析</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>BatchNorm2d(<span style=color:#ae81ff>128</span>) <span style=color:#75715e># 修正參數</span>
</span></span><span style=display:flex><span>        )
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>shortcutlayers128 <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Sequential(
</span></span><span style=display:flex><span>            <span style=color:#75715e># 找出圖片特徵，在圖片中找出128個1x1大小範圍內的特徵，以間2x2位移，輸入為64層</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>64</span>, <span style=color:#ae81ff>128</span>, (<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>), stride<span style=color:#f92672>=</span>(<span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>2</span>), padding<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>), <span style=color:#75715e># 修正參數</span>
</span></span><span style=display:flex><span>            <span style=color:#75715e># 輔助層 將資料逕行整理以便後續分析</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>BatchNorm2d(<span style=color:#ae81ff>128</span>) <span style=color:#75715e># 修正參數</span>
</span></span><span style=display:flex><span>        )
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>layers256_1 <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Sequential(
</span></span><span style=display:flex><span>            <span style=color:#75715e># 找出圖片特徵，在圖片中找出256個3x3大小範圍內的特徵，以間2x2位移，輸入為128層</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>128</span>, <span style=color:#ae81ff>256</span>, (<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>3</span>), stride<span style=color:#f92672>=</span>(<span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>2</span>), padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>), 
</span></span><span style=display:flex><span>            <span style=color:#75715e># 輔助層 將資料逕行整理以便後續分析</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>BatchNorm2d(<span style=color:#ae81ff>256</span>), <span style=color:#75715e># 修正參數</span>
</span></span><span style=display:flex><span>            <span style=color:#75715e># 並將小於0值為0</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>ReLU(),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 找出圖片特徵，在圖片中找出256個3x3大小範圍內的特徵，以間1x1位移，輸入為256層</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>256</span>, <span style=color:#ae81ff>256</span>, (<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>3</span>), stride<span style=color:#f92672>=</span>(<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>), padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>), 
</span></span><span style=display:flex><span>            <span style=color:#75715e># 輔助層 將資料逕行整理以便後續分析</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>BatchNorm2d(<span style=color:#ae81ff>256</span>) <span style=color:#75715e># 修正參數</span>
</span></span><span style=display:flex><span>        )
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>layers256_2 <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Sequential(
</span></span><span style=display:flex><span>            <span style=color:#75715e># 找出圖片特徵，在圖片中找出256個3x3大小範圍內的特徵，以間1x1位移，輸入為256層</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>256</span>, <span style=color:#ae81ff>256</span>, (<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>3</span>), stride<span style=color:#f92672>=</span>(<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>), padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>), 
</span></span><span style=display:flex><span>            <span style=color:#75715e># 輔助層 將資料逕行整理以便後續分析</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>BatchNorm2d(<span style=color:#ae81ff>256</span>), <span style=color:#75715e># 修正參數</span>
</span></span><span style=display:flex><span>            <span style=color:#75715e># 並將小於0值為0</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>ReLU(),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 找出圖片特徵，在圖片中找出256個3x3大小範圍內的特徵，以間1x1位移，輸入為256層</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>256</span>, <span style=color:#ae81ff>256</span>, (<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>3</span>), stride<span style=color:#f92672>=</span>(<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>), padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>), 
</span></span><span style=display:flex><span>            <span style=color:#75715e># 輔助層 將資料逕行整理以便後續分析</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>BatchNorm2d(<span style=color:#ae81ff>256</span>) <span style=color:#75715e># 修正參數</span>
</span></span><span style=display:flex><span>        )
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>layers256_3 <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Sequential(
</span></span><span style=display:flex><span>            <span style=color:#75715e># 找出圖片特徵，在圖片中找出256個3x3大小範圍內的特徵，以間1x1位移，輸入為256層</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>256</span>, <span style=color:#ae81ff>256</span>, (<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>3</span>), stride<span style=color:#f92672>=</span>(<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>), padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>), 
</span></span><span style=display:flex><span>            <span style=color:#75715e># 輔助層 將資料逕行整理以便後續分析</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>BatchNorm2d(<span style=color:#ae81ff>256</span>), <span style=color:#75715e># 修正參數</span>
</span></span><span style=display:flex><span>            <span style=color:#75715e># 並將小於0值為0</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>ReLU(),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 找出圖片特徵，在圖片中找出256個3x3大小範圍內的特徵，以間1x1位移，輸入為256層</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>256</span>, <span style=color:#ae81ff>256</span>, (<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>3</span>), stride<span style=color:#f92672>=</span>(<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>), padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>), 
</span></span><span style=display:flex><span>            <span style=color:#75715e># 輔助層 將資料逕行整理以便後續分析</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>BatchNorm2d(<span style=color:#ae81ff>256</span>) <span style=color:#75715e># 修正參數</span>
</span></span><span style=display:flex><span>        )
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>layers256_4 <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Sequential(
</span></span><span style=display:flex><span>            <span style=color:#75715e># 找出圖片特徵，在圖片中找出256個3x3大小範圍內的特徵，以間1x1位移，輸入為256層</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>256</span>, <span style=color:#ae81ff>256</span>, (<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>3</span>), stride<span style=color:#f92672>=</span>(<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>), padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>), 
</span></span><span style=display:flex><span>            <span style=color:#75715e># 輔助層 將資料逕行整理以便後續分析</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>BatchNorm2d(<span style=color:#ae81ff>256</span>), <span style=color:#75715e># 修正參數</span>
</span></span><span style=display:flex><span>            <span style=color:#75715e># 並將小於0值為0</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>ReLU(),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 找出圖片特徵，在圖片中找出256個3x3大小範圍內的特徵，以間1x1位移，輸入為256層</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>256</span>, <span style=color:#ae81ff>256</span>, (<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>3</span>), stride<span style=color:#f92672>=</span>(<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>), padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>), 
</span></span><span style=display:flex><span>            <span style=color:#75715e># 輔助層 將資料逕行整理以便後續分析</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>BatchNorm2d(<span style=color:#ae81ff>256</span>) <span style=color:#75715e># 修正參數</span>
</span></span><span style=display:flex><span>        )
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>layers256_5 <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Sequential(
</span></span><span style=display:flex><span>            <span style=color:#75715e># 找出圖片特徵，在圖片中找出256個3x3大小範圍內的特徵，以間1x1位移，輸入為256層</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>256</span>, <span style=color:#ae81ff>256</span>, (<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>3</span>), stride<span style=color:#f92672>=</span>(<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>), padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>), 
</span></span><span style=display:flex><span>            <span style=color:#75715e># 輔助層 將資料逕行整理以便後續分析</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>BatchNorm2d(<span style=color:#ae81ff>256</span>), <span style=color:#75715e># 修正參數</span>
</span></span><span style=display:flex><span>            <span style=color:#75715e># 並將小於0值為0</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>ReLU(),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 找出圖片特徵，在圖片中找出256個3x3大小範圍內的特徵，以間1x1位移，輸入為256層</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>256</span>, <span style=color:#ae81ff>256</span>, (<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>3</span>), stride<span style=color:#f92672>=</span>(<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>), padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>), 
</span></span><span style=display:flex><span>            <span style=color:#75715e># 輔助層 將資料逕行整理以便後續分析</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>BatchNorm2d(<span style=color:#ae81ff>256</span>) <span style=color:#75715e># 修正參數</span>
</span></span><span style=display:flex><span>        )
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>layers256_6 <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Sequential(
</span></span><span style=display:flex><span>            <span style=color:#75715e># 找出圖片特徵，在圖片中找出256個3x3大小範圍內的特徵，以間1x1位移，輸入為256層</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>256</span>, <span style=color:#ae81ff>256</span>, (<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>3</span>), stride<span style=color:#f92672>=</span>(<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>), padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>), 
</span></span><span style=display:flex><span>            <span style=color:#75715e># 輔助層 將資料逕行整理以便後續分析</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>BatchNorm2d(<span style=color:#ae81ff>256</span>), <span style=color:#75715e># 修正參數</span>
</span></span><span style=display:flex><span>            <span style=color:#75715e># 並將小於0值為0</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>ReLU(),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 找出圖片特徵，在圖片中找出256個3x3大小範圍內的特徵，以間1x1位移，輸入為256層</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>256</span>, <span style=color:#ae81ff>256</span>, (<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>3</span>), stride<span style=color:#f92672>=</span>(<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>), padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>), 
</span></span><span style=display:flex><span>            <span style=color:#75715e># 輔助層 將資料逕行整理以便後續分析</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>BatchNorm2d(<span style=color:#ae81ff>256</span>) <span style=color:#75715e># 修正參數</span>
</span></span><span style=display:flex><span>        )
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>shortcutlayers256 <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Sequential(
</span></span><span style=display:flex><span>            <span style=color:#75715e># 找出圖片特徵，在圖片中找出256個1x1大小範圍內的特徵，以間2x2位移，輸入為128層</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>128</span>, <span style=color:#ae81ff>256</span>, (<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>), stride<span style=color:#f92672>=</span>(<span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>2</span>), padding<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>), <span style=color:#75715e># 修正參數</span>
</span></span><span style=display:flex><span>            <span style=color:#75715e># 輔助層 將資料逕行整理以便後續分析</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>BatchNorm2d(<span style=color:#ae81ff>256</span>) <span style=color:#75715e># 修正參數</span>
</span></span><span style=display:flex><span>        )
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>layers512_1 <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Sequential(
</span></span><span style=display:flex><span>            <span style=color:#75715e># 找出圖片特徵，在圖片中找出512個3x3大小範圍內的特徵，以間2x2位移，輸入為256層</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>256</span>, <span style=color:#ae81ff>512</span>, (<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>3</span>), stride<span style=color:#f92672>=</span>(<span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>2</span>), padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>), 
</span></span><span style=display:flex><span>            <span style=color:#75715e># 輔助層 將資料逕行整理以便後續分析</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>BatchNorm2d(<span style=color:#ae81ff>512</span>), <span style=color:#75715e># 修正參數</span>
</span></span><span style=display:flex><span>            <span style=color:#75715e># 並將小於0值為0</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>ReLU(),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 找出圖片特徵，在圖片中找出512個3x3大小範圍內的特徵，以間1x1位移，輸入為512層</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>512</span>, <span style=color:#ae81ff>512</span>, (<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>3</span>), stride<span style=color:#f92672>=</span>(<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>), padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>), 
</span></span><span style=display:flex><span>            <span style=color:#75715e># 輔助層 將資料逕行整理以便後續分析</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>BatchNorm2d(<span style=color:#ae81ff>512</span>) <span style=color:#75715e># 修正參數</span>
</span></span><span style=display:flex><span>        )
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>layers512_2 <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Sequential(
</span></span><span style=display:flex><span>            <span style=color:#75715e># 找出圖片特徵，在圖片中找出512個3x3大小範圍內的特徵，以間1x1位移，輸入為512層</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>512</span>, <span style=color:#ae81ff>512</span>, (<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>3</span>), stride<span style=color:#f92672>=</span>(<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>), padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>), 
</span></span><span style=display:flex><span>            <span style=color:#75715e># 輔助層 將資料逕行整理以便後續分析</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>BatchNorm2d(<span style=color:#ae81ff>512</span>), <span style=color:#75715e># 修正參數</span>
</span></span><span style=display:flex><span>            <span style=color:#75715e># 並將小於0值為0</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>ReLU(),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 找出圖片特徵，在圖片中找出512個3x3大小範圍內的特徵，以間1x1位移，輸入為512層</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>512</span>, <span style=color:#ae81ff>512</span>, (<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>3</span>), stride<span style=color:#f92672>=</span>(<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>), padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>), 
</span></span><span style=display:flex><span>            <span style=color:#75715e># 輔助層 將資料逕行整理以便後續分析</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>BatchNorm2d(<span style=color:#ae81ff>512</span>) <span style=color:#75715e># 修正參數</span>
</span></span><span style=display:flex><span>        )
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>layers512_3 <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Sequential(
</span></span><span style=display:flex><span>            <span style=color:#75715e># 找出圖片特徵，在圖片中找出512個3x3大小範圍內的特徵，以間1x1位移，輸入為512層</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>512</span>, <span style=color:#ae81ff>512</span>, (<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>3</span>), stride<span style=color:#f92672>=</span>(<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>), padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>), 
</span></span><span style=display:flex><span>            <span style=color:#75715e># 輔助層 將資料逕行整理以便後續分析</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>BatchNorm2d(<span style=color:#ae81ff>512</span>), <span style=color:#75715e># 修正參數</span>
</span></span><span style=display:flex><span>            <span style=color:#75715e># 並將小於0值為0</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>ReLU(),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 找出圖片特徵，在圖片中找出512個3x3大小範圍內的特徵，以間1x1位移，輸入為512層</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>512</span>, <span style=color:#ae81ff>512</span>, (<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>3</span>), stride<span style=color:#f92672>=</span>(<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>), padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>), 
</span></span><span style=display:flex><span>            <span style=color:#75715e># 輔助層 將資料逕行整理以便後續分析</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>BatchNorm2d(<span style=color:#ae81ff>512</span>) <span style=color:#75715e># 修正參數</span>
</span></span><span style=display:flex><span>        )
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>shortcutlayers512 <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Sequential(
</span></span><span style=display:flex><span>            <span style=color:#75715e># 找出圖片特徵，在圖片中找出512個1x1大小範圍內的特徵，以間2x2位移，輸入為256層</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>256</span>, <span style=color:#ae81ff>512</span>, (<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>), stride<span style=color:#f92672>=</span>(<span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>2</span>), padding<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>), <span style=color:#75715e># 修正參數</span>
</span></span><span style=display:flex><span>            <span style=color:#75715e># 輔助層 將資料逕行整理以便後續分析</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>BatchNorm2d(<span style=color:#ae81ff>512</span>) <span style=color:#75715e># 修正參數</span>
</span></span><span style=display:flex><span>        )
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        <span style=color:#75715e># ------------------ 分類器 (Classification) ------------------</span>
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>avgpool <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>AdaptiveAvgPool2d((<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>)) <span style=color:#75715e># 新增層</span>
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>classifier <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Sequential(
</span></span><span style=display:flex><span>            <span style=color:#75715e># 攤平層 將二維轉換一維</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Flatten(),
</span></span><span style=display:flex><span>            
</span></span><span style=display:flex><span>            <span style=color:#75715e># 全連接層 將攤平層整理出1000的輸出</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Linear(<span style=color:#ae81ff>512</span>, <span style=color:#ae81ff>1000</span>),
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Softmax(dim<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>        )
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 這裡的 forward 函式定義數據如何流經網路</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>forward</span>(self, x):
</span></span><span style=display:flex><span>        <span style=color:#75715e># 初始卷積層</span>
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>features_shared(x) <span style=color:#75715e># 修正層名稱</span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># 64個</span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># 儲存殘差連接的輸入</span>
</span></span><span style=display:flex><span>        shortcut <span style=color:#f92672>=</span> x
</span></span><span style=display:flex><span>        <span style=color:#75715e># 使用64層</span>
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>layers64_1(x)
</span></span><span style=display:flex><span>        <span style=color:#75715e># 將殘差輸出與跳躍連接的輸入相加</span>
</span></span><span style=display:flex><span>        x<span style=color:#f92672>+=</span>shortcut
</span></span><span style=display:flex><span>        <span style=color:#75715e># 並將小於0值為0</span>
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>layersrelu(x)
</span></span><span style=display:flex><span>        <span style=color:#75715e># 儲存殘差連接的輸入</span>
</span></span><span style=display:flex><span>        shortcut <span style=color:#f92672>=</span> x
</span></span><span style=display:flex><span>        <span style=color:#75715e># 使用64層</span>
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>layers64_2(x)
</span></span><span style=display:flex><span>        <span style=color:#75715e># 將殘差輸出與跳躍連接的輸入相加</span>
</span></span><span style=display:flex><span>        x<span style=color:#f92672>+=</span>shortcut
</span></span><span style=display:flex><span>        <span style=color:#75715e># 並將小於0值為0</span>
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>layersrelu(x)
</span></span><span style=display:flex><span>        <span style=color:#75715e># 儲存殘差連接的輸入</span>
</span></span><span style=display:flex><span>        shortcut <span style=color:#f92672>=</span> x
</span></span><span style=display:flex><span>        <span style=color:#75715e># 使用64層</span>
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>layers64_3(x)
</span></span><span style=display:flex><span>        <span style=color:#75715e># 將殘差輸出與跳躍連接的輸入相加</span>
</span></span><span style=display:flex><span>        x<span style=color:#f92672>+=</span>shortcut
</span></span><span style=display:flex><span>        <span style=color:#75715e># 並將小於0值為0</span>
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>layersrelu(x)
</span></span><span style=display:flex><span>        <span style=color:#75715e># 128個</span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># 儲存殘差連接的輸入</span>
</span></span><span style=display:flex><span>        shortcut <span style=color:#f92672>=</span> x
</span></span><span style=display:flex><span>        <span style=color:#75715e># 使用128層</span>
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>layers128_1(x)
</span></span><span style=display:flex><span>        <span style=color:#75715e># 調整大小</span>
</span></span><span style=display:flex><span>        shortcut <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>shortcutlayers128(shortcut)
</span></span><span style=display:flex><span>        <span style=color:#75715e># 將殘差輸出與跳躍連接的輸入相加</span>
</span></span><span style=display:flex><span>        x<span style=color:#f92672>+=</span>shortcut
</span></span><span style=display:flex><span>        <span style=color:#75715e># 並將小於0值為0</span>
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>layersrelu(x)
</span></span><span style=display:flex><span>        <span style=color:#75715e># 儲存殘差連接的輸入</span>
</span></span><span style=display:flex><span>        shortcut <span style=color:#f92672>=</span> x
</span></span><span style=display:flex><span>        <span style=color:#75715e># 使用128層</span>
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>layers128_2(x)
</span></span><span style=display:flex><span>        <span style=color:#75715e># 將殘差輸出與跳躍連接的輸入相加</span>
</span></span><span style=display:flex><span>        x<span style=color:#f92672>+=</span>shortcut
</span></span><span style=display:flex><span>        <span style=color:#75715e># 並將小於0值為0</span>
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>layersrelu(x)
</span></span><span style=display:flex><span>        <span style=color:#75715e># 儲存殘差連接的輸入</span>
</span></span><span style=display:flex><span>        shortcut <span style=color:#f92672>=</span> x
</span></span><span style=display:flex><span>        <span style=color:#75715e># 使用128層</span>
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>layers128_3(x)
</span></span><span style=display:flex><span>        <span style=color:#75715e># 將殘差輸出與跳躍連接的輸入相加</span>
</span></span><span style=display:flex><span>        x<span style=color:#f92672>+=</span>shortcut
</span></span><span style=display:flex><span>        <span style=color:#75715e># 並將小於0值為0</span>
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>layersrelu(x)
</span></span><span style=display:flex><span>        <span style=color:#75715e># 儲存殘差連接的輸入</span>
</span></span><span style=display:flex><span>        shortcut <span style=color:#f92672>=</span> x
</span></span><span style=display:flex><span>        <span style=color:#75715e># 使用128層</span>
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>layers128_4(x)
</span></span><span style=display:flex><span>        <span style=color:#75715e># 將殘差輸出與跳躍連接的輸入相加</span>
</span></span><span style=display:flex><span>        x<span style=color:#f92672>+=</span>shortcut
</span></span><span style=display:flex><span>        <span style=color:#75715e># 並將小於0值為0</span>
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>layersrelu(x)
</span></span><span style=display:flex><span>        <span style=color:#75715e># 256個</span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># 儲存殘差連接的輸入</span>
</span></span><span style=display:flex><span>        shortcut <span style=color:#f92672>=</span> x
</span></span><span style=display:flex><span>        <span style=color:#75715e># 使用256層</span>
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>layers256_1(x)
</span></span><span style=display:flex><span>        <span style=color:#75715e># 調整大小</span>
</span></span><span style=display:flex><span>        shortcut <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>shortcutlayers256(shortcut)
</span></span><span style=display:flex><span>        <span style=color:#75715e># 將殘差輸出與跳躍連接的輸入相加</span>
</span></span><span style=display:flex><span>        x<span style=color:#f92672>+=</span>shortcut
</span></span><span style=display:flex><span>        <span style=color:#75715e># 並將小於0值為0</span>
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>layersrelu(x)
</span></span><span style=display:flex><span>        <span style=color:#75715e># 儲存殘差連接的輸入</span>
</span></span><span style=display:flex><span>        shortcut <span style=color:#f92672>=</span> x
</span></span><span style=display:flex><span>        <span style=color:#75715e># 使用256層</span>
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>layers256_2(x)
</span></span><span style=display:flex><span>        <span style=color:#75715e># 將殘差輸出與跳躍連接的輸入相加</span>
</span></span><span style=display:flex><span>        x<span style=color:#f92672>+=</span>shortcut
</span></span><span style=display:flex><span>        <span style=color:#75715e># 並將小於0值為0</span>
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>layersrelu(x)
</span></span><span style=display:flex><span>        <span style=color:#75715e># 儲存殘差連接的輸入</span>
</span></span><span style=display:flex><span>        shortcut <span style=color:#f92672>=</span> x
</span></span><span style=display:flex><span>        <span style=color:#75715e># 使用256層</span>
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>layers256_3(x)
</span></span><span style=display:flex><span>        <span style=color:#75715e># 將殘差輸出與跳躍連接的輸入相加</span>
</span></span><span style=display:flex><span>        x<span style=color:#f92672>+=</span>shortcut
</span></span><span style=display:flex><span>        <span style=color:#75715e># 並將小於0值為0</span>
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>layersrelu(x)
</span></span><span style=display:flex><span>        <span style=color:#75715e># 儲存殘差連接的輸入</span>
</span></span><span style=display:flex><span>        shortcut <span style=color:#f92672>=</span> x
</span></span><span style=display:flex><span>        <span style=color:#75715e># 使用256層</span>
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>layers256_4(x)
</span></span><span style=display:flex><span>        <span style=color:#75715e># 將殘差輸出與跳躍連接的輸入相加</span>
</span></span><span style=display:flex><span>        x<span style=color:#f92672>+=</span>shortcut
</span></span><span style=display:flex><span>        <span style=color:#75715e># 並將小於0值為0</span>
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>layersrelu(x)
</span></span><span style=display:flex><span>        <span style=color:#75715e># 儲存殘差連接的輸入</span>
</span></span><span style=display:flex><span>        shortcut <span style=color:#f92672>=</span> x
</span></span><span style=display:flex><span>        <span style=color:#75715e># 使用256層</span>
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>layers256_5(x)
</span></span><span style=display:flex><span>        <span style=color:#75715e># 將殘差輸出與跳躍連接的輸入相加</span>
</span></span><span style=display:flex><span>        x<span style=color:#f92672>+=</span>shortcut
</span></span><span style=display:flex><span>        <span style=color:#75715e># 並將小於0值為0</span>
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>layersrelu(x)
</span></span><span style=display:flex><span>        <span style=color:#75715e># 儲存殘差連接的輸入</span>
</span></span><span style=display:flex><span>        shortcut <span style=color:#f92672>=</span> x
</span></span><span style=display:flex><span>        <span style=color:#75715e># 使用256層</span>
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>layers256_6(x)
</span></span><span style=display:flex><span>        <span style=color:#75715e># 將殘差輸出與跳躍連接的輸入相加</span>
</span></span><span style=display:flex><span>        x<span style=color:#f92672>+=</span>shortcut
</span></span><span style=display:flex><span>        <span style=color:#75715e># 並將小於0值為0</span>
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>layersrelu(x)
</span></span><span style=display:flex><span>        <span style=color:#75715e># 512個</span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># 儲存殘差連接的輸入</span>
</span></span><span style=display:flex><span>        shortcut <span style=color:#f92672>=</span> x
</span></span><span style=display:flex><span>        <span style=color:#75715e># 使用512層</span>
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>layers512_1(x)
</span></span><span style=display:flex><span>        <span style=color:#75715e># 調整大小</span>
</span></span><span style=display:flex><span>        shortcut <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>shortcutlayers512(shortcut)
</span></span><span style=display:flex><span>        <span style=color:#75715e># 將殘差輸出與跳躍連接的輸入相加</span>
</span></span><span style=display:flex><span>        x<span style=color:#f92672>+=</span>shortcut
</span></span><span style=display:flex><span>        <span style=color:#75715e># 並將小於0值為0</span>
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>layersrelu(x)
</span></span><span style=display:flex><span>        <span style=color:#75715e># 儲存殘差連接的輸入</span>
</span></span><span style=display:flex><span>        shortcut <span style=color:#f92672>=</span> x
</span></span><span style=display:flex><span>        <span style=color:#75715e># 使用512層</span>
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>layers512_2(x)
</span></span><span style=display:flex><span>        <span style=color:#75715e># 將殘差輸出與跳躍連接的輸入相加</span>
</span></span><span style=display:flex><span>        x<span style=color:#f92672>+=</span>shortcut
</span></span><span style=display:flex><span>        <span style=color:#75715e># 並將小於0值為0</span>
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>layersrelu(x)
</span></span><span style=display:flex><span>        <span style=color:#75715e># 儲存殘差連接的輸入</span>
</span></span><span style=display:flex><span>        shortcut <span style=color:#f92672>=</span> x
</span></span><span style=display:flex><span>        <span style=color:#75715e># 使用512層</span>
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>layers512_3(x)
</span></span><span style=display:flex><span>        <span style=color:#75715e># 將殘差輸出與跳躍連接的輸入相加</span>
</span></span><span style=display:flex><span>        x<span style=color:#f92672>+=</span>shortcut
</span></span><span style=display:flex><span>        <span style=color:#75715e># 並將小於0值為0</span>
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>layersrelu(x)
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        <span style=color:#75715e># 分類器 (Classification)</span>
</span></span><span style=display:flex><span>        x <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>avgpool(x) <span style=color:#75715e># 增加的層</span>
</span></span><span style=display:flex><span>        outputs <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>classifier(x)
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> outputs
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 設定損失</span>
</span></span><span style=display:flex><span>criterion <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>CrossEntropyLoss()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 設定模型</span>
</span></span><span style=display:flex><span>model <span style=color:#f92672>=</span> ResNet(num_classes<span style=color:#f92672>=</span><span style=color:#ae81ff>10</span>)<span style=color:#f92672>.</span>to(device)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 設定優化</span>
</span></span><span style=display:flex><span>optimizer <span style=color:#f92672>=</span> optim<span style=color:#f92672>.</span>Adam(model<span style=color:#f92672>.</span>parameters(), lr<span style=color:#f92672>=</span><span style=color:#ae81ff>0.001</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>NUM_EPOCHS <span style=color:#f92672>=</span> <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 設定訓練次數</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> epoch <span style=color:#f92672>in</span> range(NUM_EPOCHS):
</span></span><span style=display:flex><span>    <span style=color:#75715e># 初始化損失和準確和數量</span>
</span></span><span style=display:flex><span>    total_loss, total_correct, total_count <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 設定進度條，將訓練集載入</span>
</span></span><span style=display:flex><span>    train_loop <span style=color:#f92672>=</span> tqdm(
</span></span><span style=display:flex><span>        trainloader,
</span></span><span style=display:flex><span>        desc<span style=color:#f92672>=</span><span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Epoch </span><span style=color:#e6db74>{</span>epoch <span style=color:#f92672>+</span> <span style=color:#ae81ff>1</span><span style=color:#e6db74>}</span><span style=color:#e6db74>/</span><span style=color:#e6db74>{</span><span style=color:#ae81ff>1</span><span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>,
</span></span><span style=display:flex><span>        unit<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;batch&#34;</span>,
</span></span><span style=display:flex><span>        leave<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>
</span></span><span style=display:flex><span>    )
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 使用進度調</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> inputs, labels <span style=color:#f92672>in</span> train_loop:
</span></span><span style=display:flex><span>        <span style=color:#75715e># 訓練集設定設備</span>
</span></span><span style=display:flex><span>        inputs, labels <span style=color:#f92672>=</span> inputs<span style=color:#f92672>.</span>to(device), labels<span style=color:#f92672>.</span>to(device)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># 梯度歸零，因為pytocrh的梯度不會規零，主要原因是批次訓練</span>
</span></span><span style=display:flex><span>        optimizer<span style=color:#f92672>.</span>zero_grad()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># 執行模型</span>
</span></span><span style=display:flex><span>        outputs <span style=color:#f92672>=</span> model(inputs)
</span></span><span style=display:flex><span>        <span style=color:#75715e># 取得損失</span>
</span></span><span style=display:flex><span>        loss <span style=color:#f92672>=</span> criterion(outputs, labels)
</span></span><span style=display:flex><span>        <span style=color:#75715e># 反向傳播</span>
</span></span><span style=display:flex><span>        loss<span style=color:#f92672>.</span>backward()
</span></span><span style=display:flex><span>        <span style=color:#75715e># 更新權重</span>
</span></span><span style=display:flex><span>        optimizer<span style=color:#f92672>.</span>step()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># 顯示損失</span>
</span></span><span style=display:flex><span>        train_loop<span style=color:#f92672>.</span>set_postfix(loss<span style=color:#f92672>=</span><span style=color:#e6db74>f</span><span style=color:#e6db74>&#39;</span><span style=color:#e6db74>{</span>loss<span style=color:#f92672>.</span>item()<span style=color:#e6db74>:</span><span style=color:#e6db74>.4f</span><span style=color:#e6db74>}</span><span style=color:#e6db74>&#39;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># 轉換預測值 (argmax 獲取最高 Log-機率的索引)</span>
</span></span><span style=display:flex><span>        predicted <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>argmax(outputs, dim<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>        <span style=color:#75715e># 將預測直查詢相加次數</span>
</span></span><span style=display:flex><span>        total_correct <span style=color:#f92672>+=</span> (predicted <span style=color:#f92672>==</span> labels)<span style=color:#f92672>.</span>sum()<span style=color:#f92672>.</span>item()
</span></span><span style=display:flex><span>        <span style=color:#75715e># 加總損失</span>
</span></span><span style=display:flex><span>        total_loss <span style=color:#f92672>+=</span> loss<span style=color:#f92672>.</span>item() <span style=color:#f92672>*</span> inputs<span style=color:#f92672>.</span>size(<span style=color:#ae81ff>0</span>)
</span></span><span style=display:flex><span>        <span style=color:#75715e># 加總訓練資料數量</span>
</span></span><span style=display:flex><span>        total_count <span style=color:#f92672>+=</span> inputs<span style=color:#f92672>.</span>size(<span style=color:#ae81ff>0</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 訓練結果輸出</span>
</span></span><span style=display:flex><span>    train_loss_avg <span style=color:#f92672>=</span> total_loss <span style=color:#f92672>/</span> total_count
</span></span><span style=display:flex><span>    train_acc_avg <span style=color:#f92672>=</span> total_correct <span style=color:#f92672>/</span> total_count
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#39;Epoch </span><span style=color:#e6db74>{</span>epoch<span style=color:#f92672>+</span><span style=color:#ae81ff>1</span><span style=color:#e6db74>}</span><span style=color:#e6db74>/</span><span style=color:#e6db74>{</span>NUM_EPOCHS<span style=color:#e6db74>}</span><span style=color:#e6db74> - loss: </span><span style=color:#e6db74>{</span>train_loss_avg<span style=color:#e6db74>:</span><span style=color:#e6db74>.4f</span><span style=color:#e6db74>}</span><span style=color:#e6db74> - acc: </span><span style=color:#e6db74>{</span>train_acc_avg<span style=color:#e6db74>:</span><span style=color:#e6db74>.4f</span><span style=color:#e6db74>}</span><span style=color:#e6db74>&#39;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 切換到評估模式</span>
</span></span><span style=display:flex><span>model<span style=color:#f92672>.</span>eval()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>correct <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span>total <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span><span style=color:#75715e># 不計算梯度</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>with</span> torch<span style=color:#f92672>.</span>no_grad():
</span></span><span style=display:flex><span>    <span style=color:#75715e># 初始化損失和準確和數量</span>
</span></span><span style=display:flex><span>    total_loss, total_correct, total_count <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> inputs, labels <span style=color:#f92672>in</span> tqdm(valloader, desc<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;驗證 (Validation)&#34;</span>, unit<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;batch&#34;</span>):
</span></span><span style=display:flex><span>        <span style=color:#75715e># 驗證集設定設備</span>
</span></span><span style=display:flex><span>        inputs, labels <span style=color:#f92672>=</span> inputs<span style=color:#f92672>.</span>to(device), labels<span style=color:#f92672>.</span>to(device)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># 執行模型</span>
</span></span><span style=display:flex><span>        outputs <span style=color:#f92672>=</span> model(inputs)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># 取得損失</span>
</span></span><span style=display:flex><span>        loss <span style=color:#f92672>=</span> criterion(outputs, labels)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># 轉換預測值</span>
</span></span><span style=display:flex><span>        predicted <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>argmax(outputs, dim<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>        <span style=color:#75715e># 將預測直查詢相加次數</span>
</span></span><span style=display:flex><span>        total_correct <span style=color:#f92672>+=</span> (predicted <span style=color:#f92672>==</span> labels)<span style=color:#f92672>.</span>sum()<span style=color:#f92672>.</span>item()
</span></span><span style=display:flex><span>        <span style=color:#75715e># 加總損失</span>
</span></span><span style=display:flex><span>        total_loss <span style=color:#f92672>+=</span> loss<span style=color:#f92672>.</span>item() <span style=color:#f92672>*</span> inputs<span style=color:#f92672>.</span>size(<span style=color:#ae81ff>0</span>)
</span></span><span style=display:flex><span>        <span style=color:#75715e># 加總訓練資料數量</span>
</span></span><span style=display:flex><span>        total_count <span style=color:#f92672>+=</span> inputs<span style=color:#f92672>.</span>size(<span style=color:#ae81ff>0</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>&#39;=&#39;</span><span style=color:#f92672>*</span><span style=color:#ae81ff>50</span>)
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#39;驗證結果 - loss: </span><span style=color:#e6db74>{</span>total_loss <span style=color:#f92672>/</span> total_count<span style=color:#e6db74>:</span><span style=color:#e6db74>.4f</span><span style=color:#e6db74>}</span><span style=color:#e6db74> - acc: </span><span style=color:#e6db74>{</span>total_correct <span style=color:#f92672>/</span> total_count<span style=color:#e6db74>:</span><span style=color:#e6db74>.4f</span><span style=color:#e6db74>}</span><span style=color:#e6db74>&#39;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>&#39;=&#39;</span><span style=color:#f92672>*</span><span style=color:#ae81ff>50</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 初始化損失和準確和數量</span>
</span></span><span style=display:flex><span>    total_loss, total_correct, total_count <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> inputs, labels <span style=color:#f92672>in</span> tqdm(testloader, desc<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;最終測試 (Testing)&#34;</span>, unit<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;batch&#34;</span>):
</span></span><span style=display:flex><span>        <span style=color:#75715e># 測試集設定設備</span>
</span></span><span style=display:flex><span>        inputs, labels <span style=color:#f92672>=</span> inputs<span style=color:#f92672>.</span>to(device), labels<span style=color:#f92672>.</span>to(device)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># 執行模型</span>
</span></span><span style=display:flex><span>        outputs <span style=color:#f92672>=</span> model(inputs)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># 取得損失</span>
</span></span><span style=display:flex><span>        loss <span style=color:#f92672>=</span> criterion(outputs, labels)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># 轉換預測值</span>
</span></span><span style=display:flex><span>        predicted <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>argmax(outputs, dim<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>        <span style=color:#75715e># 將預測直查詢相加次數</span>
</span></span><span style=display:flex><span>        total_correct <span style=color:#f92672>+=</span> (predicted <span style=color:#f92672>==</span> labels)<span style=color:#f92672>.</span>sum()<span style=color:#f92672>.</span>item()
</span></span><span style=display:flex><span>        <span style=color:#75715e># 加總損失</span>
</span></span><span style=display:flex><span>        total_loss <span style=color:#f92672>+=</span> loss<span style=color:#f92672>.</span>item() <span style=color:#f92672>*</span> inputs<span style=color:#f92672>.</span>size(<span style=color:#ae81ff>0</span>)
</span></span><span style=display:flex><span>        <span style=color:#75715e># 加總訓練資料數量</span>
</span></span><span style=display:flex><span>        total_count <span style=color:#f92672>+=</span> inputs<span style=color:#f92672>.</span>size(<span style=color:#ae81ff>0</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>&#39;=&#39;</span><span style=color:#f92672>*</span><span style=color:#ae81ff>50</span>)
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#39;測試集結果 - loss: </span><span style=color:#e6db74>{</span>total_loss <span style=color:#f92672>/</span> total_count<span style=color:#e6db74>:</span><span style=color:#e6db74>.4f</span><span style=color:#e6db74>}</span><span style=color:#e6db74> - acc: </span><span style=color:#e6db74>{</span>total_correct <span style=color:#f92672>/</span> total_count<span style=color:#e6db74>:</span><span style=color:#e6db74>.4f</span><span style=color:#e6db74>}</span><span style=color:#e6db74>&#39;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 切換到訓練模式</span>
</span></span><span style=display:flex><span>model<span style=color:#f92672>.</span>train()
</span></span></code></pre></div><h3 id=vgg>VGG</h3><p>cnn稍微進化</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py><span style=display:flex><span><span style=color:#f92672>import</span> torch
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> torch <span style=color:#f92672>import</span> nn, optim
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> torch.utils.data <span style=color:#f92672>import</span> TensorDataset, DataLoader, random_split
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> torchvision <span style=color:#f92672>import</span> datasets, transforms
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> tqdm <span style=color:#f92672>import</span> tqdm
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 使用顯卡或cpu執行</span>
</span></span><span style=display:flex><span>device <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>device(<span style=color:#e6db74>&#39;cuda&#39;</span> <span style=color:#66d9ef>if</span> torch<span style=color:#f92672>.</span>cuda<span style=color:#f92672>.</span>is_available() <span style=color:#66d9ef>else</span> <span style=color:#e6db74>&#39;cpu&#39;</span>)
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;使用的設備: </span><span style=color:#e6db74>{</span>device<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 將資料轉換</span>
</span></span><span style=display:flex><span>transform <span style=color:#f92672>=</span> transforms<span style=color:#f92672>.</span>Compose([
</span></span><span style=display:flex><span>    <span style=color:#75715e># 更改圖片大小</span>
</span></span><span style=display:flex><span>    transforms<span style=color:#f92672>.</span>Resize(<span style=color:#ae81ff>224</span>),
</span></span><span style=display:flex><span>    <span style=color:#75715e># 將資料轉換Tensor 格式</span>
</span></span><span style=display:flex><span>    transforms<span style=color:#f92672>.</span>PILToTensor(),
</span></span><span style=display:flex><span>    <span style=color:#75715e># 轉換型態</span>
</span></span><span style=display:flex><span>    transforms<span style=color:#f92672>.</span>ConvertImageDtype(torch<span style=color:#f92672>.</span>float)
</span></span><span style=display:flex><span>])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 載入訓練集，載入位置，是否為訓練集，如果沒有就下載</span>
</span></span><span style=display:flex><span>trainset <span style=color:#f92672>=</span> datasets<span style=color:#f92672>.</span>CIFAR10(
</span></span><span style=display:flex><span>    root<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;./data&#39;</span>,
</span></span><span style=display:flex><span>    train<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>,
</span></span><span style=display:flex><span>    download<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>,
</span></span><span style=display:flex><span>    transform<span style=color:#f92672>=</span>transform
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span><span style=color:#75715e># 載入測試集，載入位置，是否為訓練集，如果沒有就下載</span>
</span></span><span style=display:flex><span>testset <span style=color:#f92672>=</span> datasets<span style=color:#f92672>.</span>CIFAR10(
</span></span><span style=display:flex><span>    root<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;./data&#39;</span>,
</span></span><span style=display:flex><span>    train<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>,
</span></span><span style=display:flex><span>    download<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>,
</span></span><span style=display:flex><span>    transform<span style=color:#f92672>=</span>transform
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 分割訓練集8:2分 (訓練集與驗證集)</span>
</span></span><span style=display:flex><span>train_size <span style=color:#f92672>=</span> int((<span style=color:#ae81ff>1</span> <span style=color:#f92672>-</span> <span style=color:#ae81ff>0.2</span>) <span style=color:#f92672>*</span> len(trainset))
</span></span><span style=display:flex><span>val_size <span style=color:#f92672>=</span> len(trainset) <span style=color:#f92672>-</span> train_size
</span></span><span style=display:flex><span>train_dataset, val_dataset <span style=color:#f92672>=</span> random_split(trainset, [train_size, val_size])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 資料集分群批</span>
</span></span><span style=display:flex><span>BATCH_SIZE <span style=color:#f92672>=</span> <span style=color:#ae81ff>64</span>
</span></span><span style=display:flex><span>trainloader <span style=color:#f92672>=</span> DataLoader(train_dataset, batch_size<span style=color:#f92672>=</span>BATCH_SIZE, shuffle<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span><span style=display:flex><span>valloader <span style=color:#f92672>=</span> DataLoader(val_dataset, batch_size<span style=color:#f92672>=</span>BATCH_SIZE, shuffle<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>)
</span></span><span style=display:flex><span>testloader <span style=color:#f92672>=</span> DataLoader(testset, batch_size<span style=color:#f92672>=</span>BATCH_SIZE, shuffle<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 模型</span>
</span></span><span style=display:flex><span>model <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Sequential(
</span></span><span style=display:flex><span>            <span style=color:#75715e># 找出圖片特徵，在圖片中找出64個3x3大小範圍內的特徵，並在周圍補0，輸入為3層</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>64</span>, kernel_size<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span>, padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>), 
</span></span><span style=display:flex><span>            <span style=color:#75715e># 將小於0值為0</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>ReLU(inplace<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 卷積層 找出圖片特徵，在圖片中找出64個3x3大小範圍內的特徵，並在周圍補0，輸入為64層</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>64</span>, <span style=color:#ae81ff>64</span>, kernel_size<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span>, padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 將小於0值為0</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>ReLU(inplace<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 池化層 減少值數量找到最大值，以2x2大小找，以間2x2位移</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>MaxPool2d(kernel_size<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>, stride<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>), 
</span></span><span style=display:flex><span>            <span style=color:#75715e># 卷積層 找出圖片特徵，在圖片中找出128個3x3大小範圍內的特徵，並在周圍補0，輸入為64層</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>64</span>, <span style=color:#ae81ff>128</span>, kernel_size<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span>, padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 將小於0值為0</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>ReLU(inplace<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 卷積層 找出圖片特徵，在圖片中找出128個3x3大小範圍內的特徵，並在周圍補0，輸入為128層</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>128</span>, <span style=color:#ae81ff>128</span>, kernel_size<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span>, padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 將小於0值為0</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>ReLU(inplace<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 池化層 減少值數量找到最大值，以2x2大小找，以間2x2位移</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>MaxPool2d(kernel_size<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>, stride<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 卷積層 找出圖片特徵，在圖片中找出256個3x3大小範圍內的特徵，並在周圍補0，輸入為128層</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>128</span>, <span style=color:#ae81ff>256</span>, kernel_size<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span>, padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 將小於0值為0</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>ReLU(inplace<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 卷積層 找出圖片特徵，在圖片中找出256個3x3大小範圍內的特徵，並在周圍補0，輸入為256層</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>256</span>, <span style=color:#ae81ff>256</span>, kernel_size<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span>, padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 將小於0值為0</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>ReLU(inplace<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 卷積層 找出圖片特徵，在圖片中找出256個3x3大小範圍內的特徵，並在周圍補0，輸入為256層</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>256</span>, <span style=color:#ae81ff>256</span>, kernel_size<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span>, padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 將小於0值為0</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>ReLU(inplace<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 池化層 減少值數量找到最大值，以2x2大小找，以間2x2位移</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>MaxPool2d(kernel_size<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>, stride<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 卷積層 找出圖片特徵，在圖片中找出512個3x3大小範圍內的特徵，並在周圍補0，輸入為256層</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>256</span>, <span style=color:#ae81ff>512</span>, kernel_size<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span>, padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 將小於0值為0</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>ReLU(inplace<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 卷積層 找出圖片特徵，在圖片中找出512個3x3大小範圍內的特徵，並在周圍補0，輸入為512層</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>512</span>, <span style=color:#ae81ff>512</span>, kernel_size<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span>, padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 將小於0值為0</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>ReLU(inplace<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 卷積層 找出圖片特徵，在圖片中找出512個3x3大小範圍內的特徵，並在周圍補0，輸入為512層</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>512</span>, <span style=color:#ae81ff>512</span>, kernel_size<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span>, padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 將小於0值為0</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>ReLU(inplace<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 池化層 減少值數量找到最大值，以2x2大小找，以間2x2位移</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>MaxPool2d(kernel_size<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>, stride<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 卷積層 找出圖片特徵，在圖片中找出512個3x3大小範圍內的特徵，並在周圍補0，輸入為512層</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>512</span>, <span style=color:#ae81ff>512</span>, kernel_size<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span>, padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 將小於0值為0</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>ReLU(inplace<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 卷積層 找出圖片特徵，在圖片中找出512個3x3大小範圍內的特徵，並在周圍補0，輸入為512層</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>512</span>, <span style=color:#ae81ff>512</span>, kernel_size<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span>, padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 將小於0值為0</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>ReLU(inplace<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 卷積層 找出圖片特徵，在圖片中找出512個3x3大小範圍內的特徵，並在周圍補0，輸入為512層</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>512</span>, <span style=color:#ae81ff>512</span>, kernel_size<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span>, padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 將小於0值為0</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>ReLU(inplace<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 池化層 減少值數量找到最大值，以2x2大小找，以間2x2位移</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>MaxPool2d(kernel_size<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>, stride<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>),
</span></span><span style=display:flex><span>            
</span></span><span style=display:flex><span>            <span style=color:#75715e># 攤平層 將二維轉換一維</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Flatten(),
</span></span><span style=display:flex><span>            
</span></span><span style=display:flex><span>            <span style=color:#75715e># 全連接層 將攤平層整理出4096的輸出</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Linear(<span style=color:#ae81ff>512</span> <span style=color:#f92672>*</span> <span style=color:#ae81ff>7</span> <span style=color:#f92672>*</span> <span style=color:#ae81ff>7</span>, <span style=color:#ae81ff>4096</span>),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 將小於0值為0</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>ReLU(inplace<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 全連接層 將攤平層整理出4096的輸出</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Linear(<span style=color:#ae81ff>4096</span>, <span style=color:#ae81ff>4096</span>),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 將小於0值為0</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>ReLU(inplace<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>),
</span></span><span style=display:flex><span>            <span style=color:#75715e># 全連接層 最後整理輸出訓練集所分類的10個</span>
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Linear(<span style=color:#ae81ff>4096</span>, <span style=color:#ae81ff>10</span>),
</span></span><span style=display:flex><span>            nn<span style=color:#f92672>.</span>Softmax(dim<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>)<span style=color:#f92672>.</span>to(device)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 設定損失</span>
</span></span><span style=display:flex><span>criterion <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>CrossEntropyLoss()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 設定優化</span>
</span></span><span style=display:flex><span>optimizer <span style=color:#f92672>=</span> optim<span style=color:#f92672>.</span>Adam(model<span style=color:#f92672>.</span>parameters(), lr<span style=color:#f92672>=</span><span style=color:#ae81ff>0.001</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>NUM_EPOCHS <span style=color:#f92672>=</span> <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 設定訓練次數</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> epoch <span style=color:#f92672>in</span> range(NUM_EPOCHS):
</span></span><span style=display:flex><span>    <span style=color:#75715e># 初始化損失和準確和數量</span>
</span></span><span style=display:flex><span>    total_loss, total_correct, total_count <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 設定進度條，將訓練集載入</span>
</span></span><span style=display:flex><span>    train_loop <span style=color:#f92672>=</span> tqdm(
</span></span><span style=display:flex><span>        trainloader,
</span></span><span style=display:flex><span>        desc<span style=color:#f92672>=</span><span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Epoch </span><span style=color:#e6db74>{</span>epoch <span style=color:#f92672>+</span> <span style=color:#ae81ff>1</span><span style=color:#e6db74>}</span><span style=color:#e6db74>/</span><span style=color:#e6db74>{</span><span style=color:#ae81ff>1</span><span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>,
</span></span><span style=display:flex><span>        unit<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;batch&#34;</span>,
</span></span><span style=display:flex><span>        leave<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>
</span></span><span style=display:flex><span>    )
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 使用進度調</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> inputs, labels <span style=color:#f92672>in</span> train_loop:
</span></span><span style=display:flex><span>        <span style=color:#75715e># 訓練集設定設備</span>
</span></span><span style=display:flex><span>        inputs, labels <span style=color:#f92672>=</span> inputs<span style=color:#f92672>.</span>to(device), labels<span style=color:#f92672>.</span>to(device)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># 梯度歸零，因為pytocrh的梯度不會規零，主要原因是批次訓練</span>
</span></span><span style=display:flex><span>        optimizer<span style=color:#f92672>.</span>zero_grad()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># 執行模型</span>
</span></span><span style=display:flex><span>        outputs <span style=color:#f92672>=</span> model(inputs)
</span></span><span style=display:flex><span>        <span style=color:#75715e># 取得損失</span>
</span></span><span style=display:flex><span>        loss <span style=color:#f92672>=</span> criterion(outputs, labels)
</span></span><span style=display:flex><span>        <span style=color:#75715e># 反向傳播</span>
</span></span><span style=display:flex><span>        loss<span style=color:#f92672>.</span>backward()
</span></span><span style=display:flex><span>        <span style=color:#75715e># 更新權重</span>
</span></span><span style=display:flex><span>        optimizer<span style=color:#f92672>.</span>step()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># 顯示損失</span>
</span></span><span style=display:flex><span>        train_loop<span style=color:#f92672>.</span>set_postfix(loss<span style=color:#f92672>=</span><span style=color:#e6db74>f</span><span style=color:#e6db74>&#39;</span><span style=color:#e6db74>{</span>loss<span style=color:#f92672>.</span>item()<span style=color:#e6db74>:</span><span style=color:#e6db74>.4f</span><span style=color:#e6db74>}</span><span style=color:#e6db74>&#39;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># 轉換預測值 (argmax 獲取最高 Log-機率的索引)</span>
</span></span><span style=display:flex><span>        predicted <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>argmax(outputs, dim<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>        <span style=color:#75715e># 將預測直查詢相加次數</span>
</span></span><span style=display:flex><span>        total_correct <span style=color:#f92672>+=</span> (predicted <span style=color:#f92672>==</span> labels)<span style=color:#f92672>.</span>sum()<span style=color:#f92672>.</span>item()
</span></span><span style=display:flex><span>        <span style=color:#75715e># 加總損失</span>
</span></span><span style=display:flex><span>        total_loss <span style=color:#f92672>+=</span> loss<span style=color:#f92672>.</span>item() <span style=color:#f92672>*</span> inputs<span style=color:#f92672>.</span>size(<span style=color:#ae81ff>0</span>)
</span></span><span style=display:flex><span>        <span style=color:#75715e># 加總訓練資料數量</span>
</span></span><span style=display:flex><span>        total_count <span style=color:#f92672>+=</span> inputs<span style=color:#f92672>.</span>size(<span style=color:#ae81ff>0</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 訓練結果輸出</span>
</span></span><span style=display:flex><span>    train_loss_avg <span style=color:#f92672>=</span> total_loss <span style=color:#f92672>/</span> total_count
</span></span><span style=display:flex><span>    train_acc_avg <span style=color:#f92672>=</span> total_correct <span style=color:#f92672>/</span> total_count
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#39;Epoch </span><span style=color:#e6db74>{</span>epoch<span style=color:#f92672>+</span><span style=color:#ae81ff>1</span><span style=color:#e6db74>}</span><span style=color:#e6db74>/</span><span style=color:#e6db74>{</span>NUM_EPOCHS<span style=color:#e6db74>}</span><span style=color:#e6db74> - loss: </span><span style=color:#e6db74>{</span>train_loss_avg<span style=color:#e6db74>:</span><span style=color:#e6db74>.4f</span><span style=color:#e6db74>}</span><span style=color:#e6db74> - acc: </span><span style=color:#e6db74>{</span>train_acc_avg<span style=color:#e6db74>:</span><span style=color:#e6db74>.4f</span><span style=color:#e6db74>}</span><span style=color:#e6db74>&#39;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 切換到評估模式</span>
</span></span><span style=display:flex><span>model<span style=color:#f92672>.</span>eval()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>correct <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span>total <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span><span style=color:#75715e># 不計算梯度</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>with</span> torch<span style=color:#f92672>.</span>no_grad():
</span></span><span style=display:flex><span>    <span style=color:#75715e># 初始化損失和準確和數量</span>
</span></span><span style=display:flex><span>    total_loss, total_correct, total_count <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> inputs, labels <span style=color:#f92672>in</span> tqdm(valloader, desc<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;驗證 (Validation)&#34;</span>, unit<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;batch&#34;</span>):
</span></span><span style=display:flex><span>        <span style=color:#75715e># 驗證集設定設備</span>
</span></span><span style=display:flex><span>        inputs, labels <span style=color:#f92672>=</span> inputs<span style=color:#f92672>.</span>to(device), labels<span style=color:#f92672>.</span>to(device)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># 執行模型</span>
</span></span><span style=display:flex><span>        outputs <span style=color:#f92672>=</span> model(inputs)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># 取得損失</span>
</span></span><span style=display:flex><span>        loss <span style=color:#f92672>=</span> criterion(outputs, labels)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># 轉換預測值</span>
</span></span><span style=display:flex><span>        predicted <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>argmax(outputs, dim<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>        <span style=color:#75715e># 將預測直查詢相加次數</span>
</span></span><span style=display:flex><span>        total_correct <span style=color:#f92672>+=</span> (predicted <span style=color:#f92672>==</span> labels)<span style=color:#f92672>.</span>sum()<span style=color:#f92672>.</span>item()
</span></span><span style=display:flex><span>        <span style=color:#75715e># 加總損失</span>
</span></span><span style=display:flex><span>        total_loss <span style=color:#f92672>+=</span> loss<span style=color:#f92672>.</span>item() <span style=color:#f92672>*</span> inputs<span style=color:#f92672>.</span>size(<span style=color:#ae81ff>0</span>)
</span></span><span style=display:flex><span>        <span style=color:#75715e># 加總訓練資料數量</span>
</span></span><span style=display:flex><span>        total_count <span style=color:#f92672>+=</span> inputs<span style=color:#f92672>.</span>size(<span style=color:#ae81ff>0</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>&#39;=&#39;</span><span style=color:#f92672>*</span><span style=color:#ae81ff>50</span>)
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#39;驗證結果 - loss: </span><span style=color:#e6db74>{</span>total_loss <span style=color:#f92672>/</span> total_count<span style=color:#e6db74>:</span><span style=color:#e6db74>.4f</span><span style=color:#e6db74>}</span><span style=color:#e6db74> - acc: </span><span style=color:#e6db74>{</span>total_correct <span style=color:#f92672>/</span> total_count<span style=color:#e6db74>:</span><span style=color:#e6db74>.4f</span><span style=color:#e6db74>}</span><span style=color:#e6db74>&#39;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>&#39;=&#39;</span><span style=color:#f92672>*</span><span style=color:#ae81ff>50</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 初始化損失和準確和數量</span>
</span></span><span style=display:flex><span>    total_loss, total_correct, total_count <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> inputs, labels <span style=color:#f92672>in</span> tqdm(testloader, desc<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;最終測試 (Testing)&#34;</span>, unit<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;batch&#34;</span>):
</span></span><span style=display:flex><span>        <span style=color:#75715e># 測試集設定設備</span>
</span></span><span style=display:flex><span>        inputs, labels <span style=color:#f92672>=</span> inputs<span style=color:#f92672>.</span>to(device), labels<span style=color:#f92672>.</span>to(device)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># 執行模型</span>
</span></span><span style=display:flex><span>        outputs <span style=color:#f92672>=</span> model(inputs)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># 取得損失</span>
</span></span><span style=display:flex><span>        loss <span style=color:#f92672>=</span> criterion(outputs, labels)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># 轉換預測值</span>
</span></span><span style=display:flex><span>        predicted <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>argmax(outputs, dim<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>        <span style=color:#75715e># 將預測直查詢相加次數</span>
</span></span><span style=display:flex><span>        total_correct <span style=color:#f92672>+=</span> (predicted <span style=color:#f92672>==</span> labels)<span style=color:#f92672>.</span>sum()<span style=color:#f92672>.</span>item()
</span></span><span style=display:flex><span>        <span style=color:#75715e># 加總損失</span>
</span></span><span style=display:flex><span>        total_loss <span style=color:#f92672>+=</span> loss<span style=color:#f92672>.</span>item() <span style=color:#f92672>*</span> inputs<span style=color:#f92672>.</span>size(<span style=color:#ae81ff>0</span>)
</span></span><span style=display:flex><span>        <span style=color:#75715e># 加總訓練資料數量</span>
</span></span><span style=display:flex><span>        total_count <span style=color:#f92672>+=</span> inputs<span style=color:#f92672>.</span>size(<span style=color:#ae81ff>0</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>&#39;=&#39;</span><span style=color:#f92672>*</span><span style=color:#ae81ff>50</span>)
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#39;測試集結果 - loss: </span><span style=color:#e6db74>{</span>total_loss <span style=color:#f92672>/</span> total_count<span style=color:#e6db74>:</span><span style=color:#e6db74>.4f</span><span style=color:#e6db74>}</span><span style=color:#e6db74> - acc: </span><span style=color:#e6db74>{</span>total_correct <span style=color:#f92672>/</span> total_count<span style=color:#e6db74>:</span><span style=color:#e6db74>.4f</span><span style=color:#e6db74>}</span><span style=color:#e6db74>&#39;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 切換到訓練模式</span>
</span></span><span style=display:flex><span>model<span style=color:#f92672>.</span>train()
</span></span></code></pre></div><h2 id=非對稱式>非對稱式</h2><h3 id=dcgan>DCGAN</h3><p>透過讓生成器不斷從隨機噪聲中創造圖片，與試圖區分真實與虛假圖像的辨別器進行對抗訓練，從而學會產生高擬真度的圖像。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py><span style=display:flex><span><span style=color:#f92672>import</span> torch
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> torch <span style=color:#f92672>import</span> nn, optim
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> torch.utils.data <span style=color:#f92672>import</span> DataLoader
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> torchvision <span style=color:#f92672>import</span> datasets, transforms
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> tqdm <span style=color:#f92672>import</span> tqdm
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 鎖定設備為 CPU</span>
</span></span><span style=display:flex><span>device <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>device(<span style=color:#e6db74>&#34;cpu&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 將資料轉換</span>
</span></span><span style=display:flex><span>transform <span style=color:#f92672>=</span> transforms<span style=color:#f92672>.</span>Compose([
</span></span><span style=display:flex><span>    transforms<span style=color:#f92672>.</span>ToTensor(), 
</span></span><span style=display:flex><span>    <span style=color:#75715e># 轉換型態</span>
</span></span><span style=display:flex><span>    transforms<span style=color:#f92672>.</span>Normalize((<span style=color:#ae81ff>0.5</span>, <span style=color:#ae81ff>0.5</span>, <span style=color:#ae81ff>0.5</span>), (<span style=color:#ae81ff>0.5</span>, <span style=color:#ae81ff>0.5</span>, <span style=color:#ae81ff>0.5</span>)) 
</span></span><span style=display:flex><span>])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 載入訓練集，載入位置，是否為訓練集，如果沒有就下載</span>
</span></span><span style=display:flex><span>trainset <span style=color:#f92672>=</span> datasets<span style=color:#f92672>.</span>CIFAR10(
</span></span><span style=display:flex><span>    root<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;./data&#39;</span>, 
</span></span><span style=display:flex><span>    train<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>, 
</span></span><span style=display:flex><span>    download<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>,
</span></span><span style=display:flex><span>    transform<span style=color:#f92672>=</span>transform
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span><span style=color:#75715e># 載入測試集，載入位置，是否為訓練集，如果沒有就下載</span>
</span></span><span style=display:flex><span>testset <span style=color:#f92672>=</span> datasets<span style=color:#f92672>.</span>CIFAR10(
</span></span><span style=display:flex><span>    root<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;./data&#39;</span>, 
</span></span><span style=display:flex><span>    train<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>, 
</span></span><span style=display:flex><span>    download<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>,
</span></span><span style=display:flex><span>    transform<span style=color:#f92672>=</span>transform
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 將資料分批</span>
</span></span><span style=display:flex><span>trainloader <span style=color:#f92672>=</span> DataLoader(trainset, batch_size<span style=color:#f92672>=</span><span style=color:#ae81ff>64</span>, shuffle<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span><span style=display:flex><span>testloader <span style=color:#f92672>=</span> DataLoader(testset, batch_size<span style=color:#f92672>=</span><span style=color:#ae81ff>64</span>, shuffle<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 生成器</span>
</span></span><span style=display:flex><span>generator <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Sequential(
</span></span><span style=display:flex><span>    <span style=color:#75715e># 轉置卷積 將圖片放大512個4x4大小範圍內的特徵，以間1x1位移，並在周圍補0，關閉生成偏置，輸入為100層</span>
</span></span><span style=display:flex><span>    nn<span style=color:#f92672>.</span>ConvTranspose2d(<span style=color:#ae81ff>100</span>, <span style=color:#ae81ff>512</span>, <span style=color:#ae81ff>4</span>, <span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>0</span>, bias<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>), 
</span></span><span style=display:flex><span>    <span style=color:#75715e># 輔助層 將資料逕行整理以便後續分析</span>
</span></span><span style=display:flex><span>    nn<span style=color:#f92672>.</span>BatchNorm2d(<span style=color:#ae81ff>512</span>),
</span></span><span style=display:flex><span>    <span style=color:#75715e># 將小於等於 0 </span>
</span></span><span style=display:flex><span>    nn<span style=color:#f92672>.</span>ReLU(<span style=color:#66d9ef>True</span>),
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#75715e># 轉置卷積 將圖片放大256個4x4大小範圍內的特徵，以間2x2位移，並在周圍補0，關閉生成偏置，輸入為512層</span>
</span></span><span style=display:flex><span>    nn<span style=color:#f92672>.</span>ConvTranspose2d(<span style=color:#ae81ff>512</span>, <span style=color:#ae81ff>256</span>, <span style=color:#ae81ff>4</span>, <span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>1</span>, bias<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>), 
</span></span><span style=display:flex><span>    <span style=color:#75715e># 輔助層 將資料逕行整理以便後續分析</span>
</span></span><span style=display:flex><span>    nn<span style=color:#f92672>.</span>BatchNorm2d(<span style=color:#ae81ff>256</span>),
</span></span><span style=display:flex><span>    <span style=color:#75715e># 將小於等於 0 </span>
</span></span><span style=display:flex><span>    nn<span style=color:#f92672>.</span>ReLU(<span style=color:#66d9ef>True</span>),
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#75715e># 轉置卷積 將圖片放大128個4x4大小範圍內的特徵，以間2x2位移，並在周圍補0，關閉生成偏置，輸入為256層</span>
</span></span><span style=display:flex><span>    nn<span style=color:#f92672>.</span>ConvTranspose2d(<span style=color:#ae81ff>256</span>, <span style=color:#ae81ff>128</span>, <span style=color:#ae81ff>4</span>, <span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>1</span>, bias<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>), 
</span></span><span style=display:flex><span>    <span style=color:#75715e># 輔助層 將資料逕行整理以便後續分析</span>
</span></span><span style=display:flex><span>    nn<span style=color:#f92672>.</span>BatchNorm2d(<span style=color:#ae81ff>128</span>),
</span></span><span style=display:flex><span>    <span style=color:#75715e># 將小於等於 0 </span>
</span></span><span style=display:flex><span>    nn<span style=color:#f92672>.</span>ReLU(<span style=color:#66d9ef>True</span>),
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 轉置卷積 將圖片放大3個4x4大小範圍內的特徵，以間2x2位移，並在周圍補0，關閉生成偏置，輸入為128層</span>
</span></span><span style=display:flex><span>    nn<span style=color:#f92672>.</span>ConvTranspose2d(<span style=color:#ae81ff>128</span>, <span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>4</span>, <span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>1</span>, bias<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>), 
</span></span><span style=display:flex><span>    <span style=color:#75715e># 输出范围在 [-1, 1]</span>
</span></span><span style=display:flex><span>    nn<span style=color:#f92672>.</span>Tanh() 
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>)<span style=color:#f92672>.</span>to(device)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 判別器</span>
</span></span><span style=display:flex><span>discriminator <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Sequential(
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#75715e># 卷積層 找出圖片特徵，在圖片中找出64個5x5大小範圍內的特徵，以間2x2位移，並在周圍補0，輸入為3層</span>
</span></span><span style=display:flex><span>    nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>64</span>, (<span style=color:#ae81ff>5</span>, <span style=color:#ae81ff>5</span>), stride<span style=color:#f92672>=</span>(<span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>2</span>), padding<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>), 
</span></span><span style=display:flex><span>    <span style=color:#75715e># 將小於等於 0 的值乘上一個微小的正數</span>
</span></span><span style=display:flex><span>    nn<span style=color:#f92672>.</span>LeakyReLU(<span style=color:#ae81ff>0.2</span>, inplace<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>),
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#75715e># 卷積層 找出圖片特徵，在圖片中找出128個5x5大小範圍內的特徵，以間2x2位移，並在周圍補0，輸入為64層</span>
</span></span><span style=display:flex><span>    nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>64</span>, <span style=color:#ae81ff>128</span>, (<span style=color:#ae81ff>5</span>, <span style=color:#ae81ff>5</span>), stride<span style=color:#f92672>=</span>(<span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>2</span>), padding<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>), 
</span></span><span style=display:flex><span>    <span style=color:#75715e># 將小於等於 0 的值乘上一個微小的正數</span>
</span></span><span style=display:flex><span>    nn<span style=color:#f92672>.</span>LeakyReLU(<span style=color:#ae81ff>0.2</span>, inplace<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>),
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 卷積層 找出圖片特徵，在圖片中找出256個5x5大小範圍內的特徵，以間2x2位移，並在周圍補0，輸入為128層</span>
</span></span><span style=display:flex><span>    nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>128</span>, <span style=color:#ae81ff>256</span>, (<span style=color:#ae81ff>5</span>, <span style=color:#ae81ff>5</span>), stride<span style=color:#f92672>=</span>(<span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>2</span>), padding<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>), 
</span></span><span style=display:flex><span>    <span style=color:#75715e># 將小於等於 0 的值乘上一個微小的正數</span>
</span></span><span style=display:flex><span>    nn<span style=color:#f92672>.</span>LeakyReLU(<span style=color:#ae81ff>0.2</span>, inplace<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>),
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 卷積層 找出圖片特徵，在圖片中找出512個5x5大小範圍內的特徵，以間2x2位移，並在周圍補0，輸入為256層</span>
</span></span><span style=display:flex><span>    nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>256</span>, <span style=color:#ae81ff>512</span>, (<span style=color:#ae81ff>5</span>, <span style=color:#ae81ff>5</span>), stride<span style=color:#f92672>=</span>(<span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>2</span>), padding<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>), 
</span></span><span style=display:flex><span>    <span style=color:#75715e># 將小於等於 0 的值乘上一個微小的正數</span>
</span></span><span style=display:flex><span>    nn<span style=color:#f92672>.</span>LeakyReLU(<span style=color:#ae81ff>0.2</span>, inplace<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>),
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 攤平層 將二維轉換一維</span>
</span></span><span style=display:flex><span>    nn<span style=color:#f92672>.</span>Flatten(),
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#75715e># 全連接層 整理輸出</span>
</span></span><span style=display:flex><span>    nn<span style=color:#f92672>.</span>Linear(<span style=color:#ae81ff>512</span> <span style=color:#f92672>*</span> <span style=color:#ae81ff>2</span> <span style=color:#f92672>*</span> <span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>1</span>), 
</span></span><span style=display:flex><span>    nn<span style=color:#f92672>.</span>Sigmoid()
</span></span><span style=display:flex><span>)<span style=color:#f92672>.</span>to(device)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 設定損失</span>
</span></span><span style=display:flex><span>criterion <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>BCELoss() 
</span></span><span style=display:flex><span><span style=color:#75715e># 設定優化</span>
</span></span><span style=display:flex><span>generator_optimizer <span style=color:#f92672>=</span> optim<span style=color:#f92672>.</span>Adam(generator<span style=color:#f92672>.</span>parameters(), lr<span style=color:#f92672>=</span><span style=color:#ae81ff>0.0001</span>,betas<span style=color:#f92672>=</span>(<span style=color:#ae81ff>0.5</span>, <span style=color:#ae81ff>0.999</span>))
</span></span><span style=display:flex><span>discriminator_optimizer <span style=color:#f92672>=</span> optim<span style=color:#f92672>.</span>Adam(discriminator<span style=color:#f92672>.</span>parameters(), lr<span style=color:#f92672>=</span><span style=color:#ae81ff>0.00005</span>,betas<span style=color:#f92672>=</span>(<span style=color:#ae81ff>0.5</span>, <span style=color:#ae81ff>0.999</span>))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>real_label_val <span style=color:#f92672>=</span> <span style=color:#ae81ff>1.0</span>
</span></span><span style=display:flex><span>fake_label_val <span style=color:#f92672>=</span> <span style=color:#ae81ff>0.0</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 設定訓練次數</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> epoch <span style=color:#f92672>in</span> range(<span style=color:#ae81ff>1</span>):
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#75715e># 設定進度條，將訓練集載入</span>
</span></span><span style=display:flex><span>    train_loop <span style=color:#f92672>=</span> tqdm(
</span></span><span style=display:flex><span>        trainloader, 
</span></span><span style=display:flex><span>        desc<span style=color:#f92672>=</span><span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Epoch </span><span style=color:#e6db74>{</span>epoch <span style=color:#f92672>+</span> <span style=color:#ae81ff>1</span><span style=color:#e6db74>}</span><span style=color:#e6db74>/</span><span style=color:#e6db74>{</span><span style=color:#ae81ff>1</span><span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>, 
</span></span><span style=display:flex><span>        unit<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;batch&#34;</span>,
</span></span><span style=display:flex><span>        leave<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>
</span></span><span style=display:flex><span>    )
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#75715e># 使用進度調</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> inputs, labels <span style=color:#f92672>in</span> train_loop:
</span></span><span style=display:flex><span>        <span style=color:#75715e># 訓練集設定設備</span>
</span></span><span style=display:flex><span>        inputs<span style=color:#f92672>=</span> inputs<span style=color:#f92672>.</span>to(device)
</span></span><span style=display:flex><span>        b_size <span style=color:#f92672>=</span> inputs<span style=color:#f92672>.</span>size(<span style=color:#ae81ff>0</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># 建立隨機噪音</span>
</span></span><span style=display:flex><span>        noise <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>randn(b_size, <span style=color:#ae81ff>100</span>, <span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>, device<span style=color:#f92672>=</span>device)
</span></span><span style=display:flex><span>        <span style=color:#75715e># 讓生成器產生假圖片</span>
</span></span><span style=display:flex><span>        generated_images <span style=color:#f92672>=</span> generator(noise)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># --- D 的训练 ---</span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># 梯度歸零</span>
</span></span><span style=display:flex><span>        discriminator_optimizer<span style=color:#f92672>.</span>zero_grad() 
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        <span style=color:#75715e># 創建真標籤 (1.0)</span>
</span></span><span style=display:flex><span>        label_real <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>full((b_size,), real_label_val, dtype<span style=color:#f92672>=</span>torch<span style=color:#f92672>.</span>float, device<span style=color:#f92672>=</span>device)
</span></span><span style=display:flex><span>        <span style=color:#75715e># 讓判別器對假圖片進行預測</span>
</span></span><span style=display:flex><span>        real_output <span style=color:#f92672>=</span> discriminator(inputs)<span style=color:#f92672>.</span>view(<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>        <span style=color:#75715e># 計算損失</span>
</span></span><span style=display:flex><span>        errD_real <span style=color:#f92672>=</span> criterion(real_output, label_real)
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        <span style=color:#75715e># 讓判別器對假圖片進行預測</span>
</span></span><span style=display:flex><span>        fake_images_detached <span style=color:#f92672>=</span> generated_images<span style=color:#f92672>.</span>detach() 
</span></span><span style=display:flex><span>        fake_output_D <span style=color:#f92672>=</span> discriminator(fake_images_detached)<span style=color:#f92672>.</span>view(<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        <span style=color:#75715e># 創建假標籤 (0.0)</span>
</span></span><span style=display:flex><span>        label_fake <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>full((b_size,), fake_label_val, dtype<span style=color:#f92672>=</span>torch<span style=color:#f92672>.</span>float, device<span style=color:#f92672>=</span>device)
</span></span><span style=display:flex><span>        <span style=color:#75715e># 計算損失</span>
</span></span><span style=display:flex><span>        errD_fake <span style=color:#f92672>=</span> criterion(fake_output_D, label_fake)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># D 的總損失</span>
</span></span><span style=display:flex><span>        disc_loss <span style=color:#f92672>=</span> errD_real <span style=color:#f92672>+</span> errD_fake
</span></span><span style=display:flex><span>        <span style=color:#75715e># 反向傳播</span>
</span></span><span style=display:flex><span>        disc_loss<span style=color:#f92672>.</span>backward() 
</span></span><span style=display:flex><span>        <span style=color:#75715e># 更新權重</span>
</span></span><span style=display:flex><span>        discriminator_optimizer<span style=color:#f92672>.</span>step()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># --- G 的训练---</span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># 梯度歸零</span>
</span></span><span style=display:flex><span>        generator_optimizer<span style=color:#f92672>.</span>zero_grad()
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        <span style=color:#75715e># 讓判別器對假圖片進行預測</span>
</span></span><span style=display:flex><span>        output_for_G <span style=color:#f92672>=</span> discriminator(generated_images)<span style=color:#f92672>.</span>view(<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>) 
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        <span style=color:#75715e># 建立G 的目标真標籤 (1.0)</span>
</span></span><span style=display:flex><span>        label_target_G <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>full((b_size,), real_label_val, dtype<span style=color:#f92672>=</span>torch<span style=color:#f92672>.</span>float, device<span style=color:#f92672>=</span>device)
</span></span><span style=display:flex><span>        <span style=color:#75715e># 計算損失</span>
</span></span><span style=display:flex><span>        gen_loss <span style=color:#f92672>=</span> criterion(output_for_G, label_target_G)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># 反向傳播</span>
</span></span><span style=display:flex><span>        gen_loss<span style=color:#f92672>.</span>backward() 
</span></span><span style=display:flex><span>        <span style=color:#75715e># 更新權重</span>
</span></span><span style=display:flex><span>        generator_optimizer<span style=color:#f92672>.</span>step()
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        <span style=color:#75715e># 更新进度条信息</span>
</span></span><span style=display:flex><span>        train_loop<span style=color:#f92672>.</span>set_postfix(
</span></span><span style=display:flex><span>            Loss_D<span style=color:#f92672>=</span><span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;</span><span style=color:#e6db74>{</span>disc_loss<span style=color:#f92672>.</span>item()<span style=color:#e6db74>:</span><span style=color:#e6db74>.4f</span><span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>, 
</span></span><span style=display:flex><span>            Loss_G<span style=color:#f92672>=</span><span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;</span><span style=color:#e6db74>{</span>gen_loss<span style=color:#f92672>.</span>item()<span style=color:#e6db74>:</span><span style=color:#e6db74>.4f</span><span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>, 
</span></span><span style=display:flex><span>        )
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Epoch </span><span style=color:#e6db74>{</span>epoch <span style=color:#f92672>+</span> <span style=color:#ae81ff>1</span><span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span></code></pre></div></div><footer><div><ul class=main_page_terms_ul_class><li class=main_page_terms_li_class><div>標籤:</div></li><ul class=main_page_terms_ul_class2><li class=main_page_terms_li_class2><div class=main_page_terms_div_class>Python語言</div><a class=main_page_terms_a_class href=/tomku/tags/python%E8%AA%9E%E8%A8%80/></a></li><li class=main_page_terms_li_class2><div class=main_page_terms_div_class>筆記</div><a class=main_page_terms_a_class href=/tomku/tags/%E7%AD%86%E8%A8%98/></a></li><li class=main_page_terms_li_class2><div class=main_page_terms_div_class>Pytorch</div><a class=main_page_terms_a_class href=/tomku/tags/pytorch/></a></li><li class=main_page_terms_li_class2><div class=main_page_terms_div_class>AI</div><a class=main_page_terms_a_class href=/tomku/tags/ai/></a></li></ul></ul></div><nav class=main_page_section_nav_class><a class=main_page_section_a_class href=/tomku/python/notes/17/><samp>上一頁</samp><br><samp>python語言的筆記-tensorflow-文字AI模型</samp><br><samp><time datetime=2025-08-30T14:49:32+08:00>2025-08-30</time>
</samp></a><a class=main_page_section_a_class2 href=/tomku/python/notes/19/><samp>下一頁</samp><br><samp>python語言的筆記-pytorch-文字AI模型</samp><br><samp><time datetime=2025-10-18T15:07:01+08:00>2025-10-18</time></samp></a></nav></footer></article></section></div><aside class="main right_aside_class"><div class=right_div_class><details class=right_details_class open><summary class=right_details_class>目錄</summary><nav id=TableOfContents><ul><li><a href=#pytorch-圖像ai模型>pytorch-圖像AI模型</a><ul><li><a href=#監督式>監督式</a><ul><li><a href=#cnn>cnn</a></li><li><a href=#alexnet>alexnet</a></li><li><a href=#yolo-v1>yolo v1</a></li><li><a href=#resnet>ResNet</a></li><li><a href=#vgg>VGG</a></li></ul></li><li><a href=#非對稱式>非對稱式</a><ul><li><a href=#dcgan>DCGAN</a></li></ul></li></ul></li></ul></nav></details></div><div class=right_div_class><details class=right_related_details_class open><summary class=right_related_details_class>相關文章</summary><nav class=right_related_page_nav_class><ol class=right_related_page_ol_class></ol><hr></nav></details></div></aside></main><footer class=baseof_footer_class><center><p>Copyright @2024-2025 tomku的網誌 Powered by <a href=https://gohugo.io/>Hugo</a></p><p xmlns:cc=http://creativecommons.org/ns# xmlns:dct=http://purl.org/dc/terms/>Except where otherwise noted, <span property="dct:title">tomku的網誌</span> by <span property="cc:attributionName">YU-LUN KU</span> is licensed under <a href="http://creativecommons.org/licenses/by-sa/4.0/?ref=chooser-v1" target=_blank rel="license noopener noreferrer" style=display:inline-block>Attribution-ShareAlike 4.0 International<img style=height:22px!important;margin-left:3px;vertical-align:text-bottom;display:inline-block src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style=height:22px!important;margin-left:3px;vertical-align:text-bottom;display:inline-block src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"><img style=height:22px!important;margin-left:3px;vertical-align:text-bottom;display:inline-block src="https://mirrors.creativecommons.org/presskit/icons/sa.svg?ref=chooser-v1"></a></p><p>若有需聯絡請寄信到tom8760925@gmail.com</p><p>若分享內容有侵害您的著作權，請來信告知，我將儘速移除相關內容</p></center></footer></body></html>